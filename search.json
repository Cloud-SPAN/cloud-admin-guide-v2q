[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automated Management of AWS Instances",
    "section": "",
    "text": "Cloud-SPAN is a project run by the Biology Department at the University of York with the aim to training researchers in the experimental design and analysis of ’omics data using cloud-based High Performance Computing (HPC) resources.\nThis course teaches how to automatically manage multiple Amazon Web Services (AWS) instances — each instance being a Linux virtual machine. Using Bash Shell scripts, we show how to create, configure, stop, start and delete one or multiple instances with a single invocation of a script.\nWe use the scripts to manage multiple instances for training. When running a workshop, instances are created with ’omics data and software required for the workshop. Each student is granted exclusive access to one instance through the use of an encrypted login key.\nTo create, configure or delete instances, the scripts require only the names of the instances. The login keys, IP addresses, and domain names used by the instances are created or deleted automatically. Creating over 30 instances takes 10-15 minutes.\nThe target audience of the course is anyone interested in deploying and managing cloud resources for training. While the course is focused on AWS, and particularly Elastic Compute Cloud (EC2) instances, the scripts can be adapted for use with other cloud providers and other types of cloud services.\nThe course is designed for 4-6 hours of self-study, depending on the number of related topics you decide to explore further.\n\n\n\n\n\n\nGetting Started\n\n\n\nThe course assumes that learners have no prior experience with the AWS concepts and tools covered in the course.\nHowever, learners are expected to have experience with both the Linux/Unix terminal and Bash shell programming — the terminal is also known as the shell and the command line interface or CLI. Windows users need to install and configure the Git Bash terminal and Mac users need to install or update the Bash shell as instructed in the Setup section; see also the Workshops Organisation below.\nLearners are also expected to use a laptop or desktop computer. Tablets and mobile phones are not suitable for taking the course, as you will be using the keyboard to type commands to the terminal or to edit text files.\n\n\n\nBackground\n“Cloud computing is the on-demand availability [through the Internet] of computer system resources [such as] data storage and computing power … [that] relies on a “pay-as-you-go” model …“[Wikipedia]. That means that we can rent as many computing resources as we need, whenever we need them, and pay only for the time we use them.\nThe main advantage of Cloud computing is that we don’t have to commit too much time and money in managing the IT resources needed to try out a new idea or experiment. Or as is the case of the Cloud-SPAN and similar projects, running hands-on training workshops by providing a properly configured instance (virtual machine) to each participant without having to handle nor invest in hardware resources nor physical space. Instead, an instance in the cloud is first configured with all the data and software tools required by a workshop. This instance is then configured as a template, or Amazon Machine Image (AMI) in AWS terminology. Finally, a number of instances is created from the AMI and configured individually as to domain name, IP address and access login key. Once the course is over, the instances are deleted to stop incurring costs. The AMI is typically preserved to serve as the starting point either (1) to create new instances for a new run of the workshop, or (2) to create a new AMI with updated data or software or both, through creating an instance, updating the data or software, and creating an AMI out of the instance.\nDespite such convenience, managing multiple instances through a Graphical User Interface (GUI), such as the AWS Console, is really cumbersome and error-prone. Hence we developed the scripts, and through their use we have noted a few best practices to manage multiple instances that are covered in the course.\n\n\nCourse Overview\n\n\n\nLesson\nOverview\n\n\n\n\n1. Setting Up Your Cloud and Terminal Environments\nLearn how to create and configure your AWS account for daily work, and how to install and configure the scripts in your Terminal environment to use your AWS account.\n\n\n2. Managing AWS Instances\nLearn how to configure your AWS account to provide AWS instances with access based on domain names and login keys, how to run the scripts to deploy and manage AWS instances for a workshop, how to create and manage AMIs, and the organisation and workings of the scripts.\n\n\n\n\n\nWorkshops Organisation\nOnline and in-person workshops of this course are delivered in 2.5 - 3 hours and are focused on the use of the scripts, covering only the episodes indicated below:\nLesson 1: Setting Up Your Cloud and Terminal Environments:\n1.1. Create Your AWS Account\n1.2. Configure Your AWS Account\n1.3. Configure Your Terminal Environment\n1.4. Configure Your AWS CloudShell Environment\nLesson 2: Managing AWS Instances:\n2.1. Configure Instances Internet Access\n2.2. Instances Management Tasks Using the Scripts — workshop\n2.3. AMIs Management — workshop\n2.4. The Scripts Design — workshop\n\nAttending a workshop with no AWS account — using a Cloud-SPAN AWS account\nYou can attend a workshop without having to create and configure an AWS account (Episodes 1.1 and 1.2). However, as an AWS account is needed to create and manage AWS instances with the scripts, as a workshop attendee, an AWS Linux instance will be made available to you at no cost by the Cloud-SPAN team. This instance will have already configured the terminal environment (Episode 1.3) and instances internet access (Episode 2.1) using a Cloud-SPAN AWS account. To login to your Linux instance you will use the (secure shell) ssh program, and hence, prior to the workshop you need to have installed ssh on your (Linux or Mac) computer – Windows users can install Git Bash as that will also install ssh on your computer, see the Setup section. You will receive instructions to login to your Linux instance at the worshop.\n\n\nAttending a workshop using your AWS account\nYou can attend a workshop and use your AWS account (or the AWS account of your institution) to use (run) the scripts. You need to complete the following episodes before the workshop (contact the Cloud-SPAN team if you need assistance):\n1.1. Create Your AWS Account\n1.2. Configure Your AWS Account\n1.3. Configure Your Terminal Environment or\n1.4. Configure Your AWS CloudShell Environment and\n2.1. Configure Instances Internet Access\nYou can configure the scripts to use your AWS account either on your computer (Episode 1.3: using either a Git Bash terminal, a Linux terminal or a Mac terminal) or on your AWS CloudShell Environment (Episode 1.4), which is a browser-based Linux terminal. If you opt for configuring the scripts on your computer: Windows users need to install Git Bash and Mac users need to install or update the Bash shell on their computer prior to the workshop, see details in the Setup section and in the introduction to Lesson 1, Setting Up Your Cloud and Terminal Environments.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/04-scripts-design.html",
    "href": "docs/lesson02-managing-aws-instances/04-scripts-design.html",
    "title": "The Scripts Design",
    "section": "",
    "text": "Tip\n\n\n\nThis episode has no hands-on activities but you should have covered the two previous episodes, Instances Management Tasks Using the Scripts and AMIs Management, to better understand the concepts presented in this episode.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "The Scripts Design"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/04-scripts-design.html#organisation-into-modules",
    "href": "docs/lesson02-managing-aws-instances/04-scripts-design.html#organisation-into-modules",
    "title": "The Scripts Design",
    "section": "Organisation into modules",
    "text": "Organisation into modules\nRecall that you run csinstances_create.sh to create one or multiple instances specified in an “instancesNames.txt” file (whose name you can choose), and that each instance is accessed with ssh using a login key and a domain name that is mapped to an IP address.\nThe main code of csinstances_create.sh is below. All it does is to run the aws_*.sh scripts that actually create instances and related resources, passing to each such script the parameter it received, the path/name of the “instancesNames.txt” file which, being the first and only parameter you specify, is stored in the script variable $1\nThe script csinstances_delete.sh is organised and works the same way but it runs the scripts that actually delete instances and related resources instead.\n\n\nOutput\n\naws_loginKeyPair_create.sh      \"$1\" || { message \"$error_message\"; exit 1; }\naws_instances_launch.sh         \"$1\" || { message \"$error_message\"; exit 1; }\naws_elasticIPs_allocate.sh      \"$1\" || { message \"$error_message\"; exit 1; }\naws_domainNames_create.sh       \"$1\" || { message \"$error_message\"; exit 1; }\naws_elasticIPs_associate2ins.sh \"$1\" || { message \"$error_message\"; exit 1; }\naws_instances_configure.sh      \"$1\" || { message \"$error_message\"; exit 1; }\nexit 0\n\nThat all means that each aws_*.sh script is in charge of:\n\na single type of AWS operation request (either create, allocate, .., deallocate, or delete)\nfor one or multiple AWS resources all of the same type (either instance, login key, domain name, or IP address).\nEach script will make an AWS operation request for each instance name specified in the file “instancesNames.txt”.\n\nSuch organisation means that all login keys are created first, then all instances are created, etc. — and vice versa: all instances are deleted first, then all login keys are deleted, etc.\nAn alternative way to organise the Scripts would be such that: each instance and its resources (login key, domain name, and IP address) are created first, then a second instance and its resources are created, and so on. But the code gets much more complicated.\n\n\n\n\n\n\nExercise\n\n\n\nThink of that alternative organisation for the Scripts or any other organisation you would like for the Scripts.\n\nIs it really more complex?\nWhy?\nHow would csinstances_create.sh be organised?\nDo we need more or fewer scripts?\n\nIf you thought of another alternative organisation, what is the main flow in creating instances and their resources?",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "The Scripts Design"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/04-scripts-design.html#the-aws_.sh-scripts-main-processing-steps",
    "href": "docs/lesson02-managing-aws-instances/04-scripts-design.html#the-aws_.sh-scripts-main-processing-steps",
    "title": "The Scripts Design",
    "section": "The aws_*.sh scripts main processing steps",
    "text": "The aws_*.sh scripts main processing steps\nEach aws_*.sh script makes an AWS operation request for each instance name specified in the file “instancesNames.txt” through these main steps:\n\nDetermine the location of relevant “shared data” from the path of the file “instancesNames.txt (received as parameter):\n\nthe path of the configuration files resourcesIDs.txt, tags.txt — required by the scripts that create instances and related resources.\nthe path of results files (in the outputs directory) that contain the AWS resources IDs — required by the scripts that delete instances and related resources, and csinstances_stop.sh and csinstances_start.sh.\n\nmakes a list of instances names from the names specified in the file “instancesNames.txt”.\nloop through the instances names list to request, for each instance, the script-relevant AWS operation through running aws passing required parameters — some extracted from the files in step 1.\n\n\n\n\n\n\n\nExercise\n\n\n\nThe code structure of csinstances_stop.sh and csinstances_start.sh is similar to that to the code structure of the aws_*.sh scripts.\nCan you figure out the reason for that (before looking at the code)?",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "The Scripts Design"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/04-scripts-design.html#the-scripts-shared-data-communication",
    "href": "docs/lesson02-managing-aws-instances/04-scripts-design.html#the-scripts-shared-data-communication",
    "title": "The Scripts Design",
    "section": "The Scripts “shared data” communication",
    "text": "The Scripts “shared data” communication\nBreaking down the functionality of the Scripts as described above, or of any software system for that matter, involves designing communication between the parts. Such communication can be based either on message passing or shared data. Message passing is explicit communication between two or more specific parts. Shared data is implicit communication: all parts know where the shared data is.\nThe Scripts use both types of communication:\n\nmessage passing is used when passing the name of an “instancesNames.txt” file to and between the Scripts.\nshared data is used when accessing data in the files in the inputs and outputs directories of a course — which is possible through using specific names and locations for those files which, in turn, makes it possible to determine their path from the path of the “instancesNames.txt” file.\n\n\nGetting the path of the inputs and outputs directories\nAll the aws_*.sh scripts get the path to the shared directories inputs and outputs thus:\n\n\nCode\n\ninstancesNamesFile=${1}               # $1 or ${1} is the path of \"instancesNames.txt\" received as parameter\ninputsDir=${1%/*}                     # inputs directory path\noutputsDir=${1%/inputs*}/outputs      # outputs directory path\n\n\n\nMaking the path of the outputs/“results” directory\nThen, each aws_*.sh script that creates instances or related resources will use only one of the assignment statements below to make the path of the directory where it will create a file to write the results of each AWS operation request that it will issue for each instance name specified in the file “instancesNames.txt”:\n\n\nCode\n\noutputsDirThisRun=${outputsDir}/login-keys-creation-output\noutputsDirThisRun=${outputsDir}/instances-creation-output\noutputsDirThisRun=${outputsDir}/ip-addresses-allocation-output  \noutputsDirThisRun=${outputsDir}/domain-names-creation-output\noutputsDirThisRun=${outputsDir}/ip-addresses-association-output\n\nEach aws_*.sh script that deletes instances or related resources will use only one of the assignment statements below, instead:\n\n\nCode\n\noutputsDirThisRun=${outputsDir}/ip-addresses-deallocate-output`date '+%Y%m%d.%H%M%S'`\noutputsDirThisRun=${outputsDir}/login-keys-delete-output`date '+%Y%m%d.%H%M%S'`\noutputsDirThisRun=${outputsDir}/instances-delete-output`date '+%Y%m%d.%H%M%S'`\noutputsDirThisRun=${outputsDir}/domain-names-delete-output`date '+%Y%m%d.%H%M%S'`\noutputsDirThisRun=${outputsDir}/ip-addresses-disassociate-output`date '+%Y%m%d.%H%M%S'`\n\nYou will remember that the results of deleting instances and related resources are written to directories whose names are suffixed with the current date and time.\n\n\nGetting the “shared data” in the files tags.txt and resourcesIDs.txt\nThe scripts aws_elasticIPs_allocate.sh, aws_instances_launch.sh and aws_loginKeyPair_create.sh load the labels in the file inputs/tags.txt into the array tags, and then copy the labels values from the tags array to variables with meaningful names:\n\n\nCode\n\ntags=( `cat $inputsDir/tags.txt` )  \ntag_name_value=${tags[1]}           \ntag_group_value=${tags[3]}\ntag_project_value=${tags[5]}\ntag_status_value=${tags[7]}\ntag_pushedby_value=${tags[9]}\ntag_definedin_value=${tags[11]}\n\nThe script aws_instances_launch.sh does similarly to get the resources IDs in the file inputs/resourcesIDs.txt:\n\n\nCode\n\nresources=( `cat $inputsDir/resourcesIDs.txt` )\nresource_image_id=${resources[1]}\nresource_instance_type=${resources[3]}\nresource_security_group_ids=${resources[5]}\nresource_subnet_id=${resources[7]}\n\nOnly the aws_instances_launch.sh uses the resources IDs.\nThe aws_*.sh scripts that delete instances or related resources don’t need nor use the “shared data” in the files tags.txt and resourcesIDs.txt.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "The Scripts Design"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/04-scripts-design.html#the-scripts-loop-through-instances-names",
    "href": "docs/lesson02-managing-aws-instances/04-scripts-design.html#the-scripts-loop-through-instances-names",
    "title": "The Scripts Design",
    "section": "The Scripts loop through instances names",
    "text": "The Scripts loop through instances names\nOnce an aws_*.sh script sets access to “shared data” as described above, the script goes through the loop where, for each instance name in the “instancesNames.txt” file, the script invokes the AWS operation request it is in charge of.\nThe loop of the script aws_instances_launch.sh (which creates one or multiple instances) is shown below. We have added the line numbers on the left for convenience but they don’t correspond to the actual line numbers in the script. Also, we have ommitted the code for Results Handling after the invokation of the AWS operation request with aws — such Results Handling is similar in all the aws_*.sh scripts.\n\n\nCode\n\n01 instancesNames=( `cat $instancesNamesFile` )\n02 for instance in ${instancesNames[@]}\n03 do\n04   logkeyend=${instance%-src*}\n05   aws ec2 run-instances --image-id $resource_image_id --instance-type $resource_instance_type\\\n06   --key-name \"login-key-${logkeyend}\"  \\\n07   --security-group-ids $resource_security_group_ids \\\n08   --subnet-id $resource_subnet_id --tag-specifications \\\n09   \"ResourceType=instance, Tags=[{Key=Name,   Value=$instance}, \\\n10                      {Key=name,      Value=${instance,,}}, \\\n11                      {Key=group, Value=$tag_group_value}, \\\n12                      {Key=project, Value=$tag_project_value}, \\\n13                      {Key=status, Value=$tag_status_value}, \\\n14                      {Key=pushed_by, Value=$tag_pushedby_value}, \\\n15                  {Key=defined_in, Value=$tag_definedin_value},  \\\n16                ]\"  $outputsDirThisRun/$instance.txt 2&1\n17   if [ $? -eq 0 ]; then\n18      ### aws Results Handling\n19   fi\n20 done\n\nLine 01: the variable instancesNames is initialised as list of the instances names in the file “instancesNames.txt” file (variable $instancesNamesFile).\nLine 02: the loop starts, using the variable instance to store the instance name in turn.\nLine 04: logkeyend=${instance%-src*} gets the end, the suffix, of the login key name to pass as parameter to aws (line 06). Each login key name is created with the fixed prefix login-key- concatenated to the instance name (in the instance variable) without the instance name suffix that identifies the source (%-src*) AMI template (discussed in episode 3).\nLines 05-16 is a single command — the character \\, at the end of lines 05-12, tells Bash to carry on reading input before running the command. The command runs the AWS CLI program aws requesting to launch and instance, passing various parameters including: --image-id (AMI id), .. and the tag values (previously loaded from the file inputs/tags.txt). The parameters to aws are discussed below.\nLine 16: the results of invoking aws are stored in the file whose name is specified by the value in the variables $outputsDirThisRun/$instance.txt which were previously defined before and within the loop, respectively. Both results (1) and any errors (2), if any, are written to that file (2&1).\n\nThe loops in the other scripts\nThe loop in each of all other aws_*.sh scripts is similar to the loop shown above in that:\n\nthe instance loop variable is used to create the name of other files to access therein data that is relevant to the function of the script. Recall that:\n“Each instance name is the key to access each instance results files in the outputs directory”.\naws is run to make the corresponding AWS operation request.\nresults and errors of invoking aws are saved to a file in the outputs/script-results/ directory.\n\nThe loop in the scripts below are somewhat different to all others:\n\naws_domainNames_create.sh:\nBefore invoking aws to create a domain name (for the instance being processed in the loop), aws_domainNames_create.sh creates a .json file with the details of the domain name to be created, and then invokes aws passing the path of that file as parameter, among other parameters.\n\naws_loginKeyPair_create.sh:\nAfter invoking aws to create a login key (for the instance being processed in the loop), if the invocation was Successful, aws_loginKeyPair_create.sh unpacks the login key from the results file (of invoking aws) into a .pem file. Such results are returned in .json format, which includes a key-value pair for each item of information returned, for example: “KeyName”: “login-key-instance01”; “KeyPairId”: “key-0f2702d75934347e4”; “KeyMaterial”: ” the login key itself “, among other items of information. The value of”KeyMaterial” is extracted from the resuts file, and somewhat processed before writing it onto a .pem file. The processing is required for the login keys to work in MacOS machines.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "The Scripts Design"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/01-configure-instances-internet.html",
    "href": "docs/lesson02-managing-aws-instances/01-configure-instances-internet.html",
    "title": "Configure Instances Internet Access",
    "section": "",
    "text": "Prerequisites\n\n\n\nPlease read Workshops Organisation if you haven’t done so. To complete this episode you will need:\n\nif you are self-studying the course or attending a workshop using your AWS account:\n\nto have created and configured your AWS account as described in Episodes 1 and 2 of Lesson 1, namely: Create Your AWS Account and Configure Your AWS Account.\nthe AWS Console login details of your IAM user account: login page, username and password.\n\nif you are attending a workshop using a Cloud-SPAN AWS account (and an AWS Linux instance), you don’t need to complete this episode.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Configure Instances Internet Access"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/01-configure-instances-internet.html#steps",
    "href": "docs/lesson02-managing-aws-instances/01-configure-instances-internet.html#steps",
    "title": "Configure Instances Internet Access",
    "section": "Steps",
    "text": "Steps\nThese are the main steps you will follow to configure internet access for the instances you will create with the Scripts:\n\nCreate Your Base Domain Name\nThe base domain name you will create will be configured so that the Scripts can create a sub-domain name for each instance. If you are using an AWS institutional account, your base domain name may itself be a sub-domain within a domain name managed by your institution. Check the callout at the end of this section to ensure your based domain name is properly configured by you or your IT department.\nCreate Your AWS Security Group\nAn AWS security group is a set of rules to configure the Internet communication ports of AWS instances. The security group you will create will enable the communication port used by the ssh program. We only need one security group as all instances need the same configuration. If you are using an AWS institutional account, you should not have any problem creating a security group — try to create it; if you cannot then contact your IT deparment.\nSelect an AWS Subnet to Access the Instances\nAn AWS subnet is a network within an AWS region to which the instances created by the Scripts will be connected so that they can be accessed from anywhere. You will select one of the subnets available in the Ireland region. If you are using an AWS institutional account, you may be able or need to use a subnet already setup by your IT department — ask them.\n\nYou are going to create those three resources using the AWS Console with your IAM user account. These are the instructions to login to your IAM account: - Open a new browser window and enter the address of the login page for your account IAM users. The address contains your account alias or your 12-digit account number and has this form: - https://youraccountalias.signin.aws.amazon.com/console - https://123456789012.signin.aws.amazon.com/console - Enter your IAM username and password. You may also get a Security check to complete. - Set the region to Ireland (eu-west-1) if it is not, by clicking on the drop-down menu on the top to the right, see top right on the page below.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Configure Instances Internet Access"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html",
    "title": "Create Your AWS Account",
    "section": "",
    "text": "Prerequisites\n\n\n\nPlease read Workshops Organisation if you haven’t done so. To complete this episode you will need: - if you are self-studying the course or attending a workshop using your AWS account: - an email address - a credit card — new accounts get one-year of AWS Free Tier but a card number must be entered on creating an account - the phone number associated with the credit card - the address associated with the credit card - if you are attending a workshop using a Cloud-SPAN AWS account (and an AWS Linux instance), you don’t need to complete this episode.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html#introduction",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html#introduction",
    "title": "Create Your AWS Account",
    "section": "Introduction",
    "text": "Introduction\nThese are the main steps you will follow to open your AWS account:\n\nSign-up to AWS with your email (as username) and password.\nSelect your account type (Personal) and enter your contact information.\nEnter Billing Information: your credit card details.\nConfirm your identity to AWS through a phone call or SMS message.\nSelect support plan (Basic) and complete sign-up.\nLogin to your AWS account.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html#sign-up-to-aws-with-your-email-and-password",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html#sign-up-to-aws-with-your-email-and-password",
    "title": "Create Your AWS Account",
    "section": "1. Sign-up to AWS with your email and password",
    "text": "1. Sign-up to AWS with your email and password\nGo to the AWS sign-up page by going to AWS sign-up — for convenience, right click on the link and, in the menu that pops up, left click on Open link in new window; you can switch between this browser window and the sign-up page window to be opened by pressing the keys Alt-Tab simultaneously.\nEnter your email and password and a name for your account — you can change the name of your account later.\n\n\n\n.\n\n\n\n\n\n\n\n\nNew accounts\n\n\n\n\nNew accounts are all granted the one-year Free Tier (message on the left).\nThe name of an account helps to identify the account once the user is logged in, as it is not uncommon for AWS users to have more than one AWS account.\n\n\n\nOnce you have entered your email, password and account name, click on Continue (step 1 of 5) and complete the Security check box that will pop up by typing the characters displayed into the box. Click on Continue (step 1 of 5) again.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html#select-your-account-type-personal-and-enter-your-contact-information",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html#select-your-account-type-personal-and-enter-your-contact-information",
    "title": "Create Your AWS Account",
    "section": "2. Select your account type (Personal) and enter your contact information",
    "text": "2. Select your account type (Personal) and enter your contact information\nThe next page asks you How do you plan to use AWS? Choose Personal and enter your name, phone number and address — your address must be the one associated with your credit card and this will be verified in the next step.\nThen read the AWS Customer Agreement and check the box I have read and agree to the terms of the AWS Customer Agreement. Finally, click on Continue (step 2 of 5) to move to step 3.\n\n\n\n.\n\n\n\n\n\n\n\n\nAccount types\n\n\n\n\nThere is no functional difference between a business account and a personal account. Both have access to all AWS services and both support managing sub-accounts which, as we will see in the next episode, are more convenient for every day work.\nA personal account should not be opened with a work email address as you may change jobs after opening the account. A business account should be opened with a company or institution address linked to a roll or position and not to a person who may change jobs at some point.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html#enter-billing-information-your-credit-card-details",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html#enter-billing-information-your-credit-card-details",
    "title": "Create Your AWS Account",
    "section": "3. Enter Billing Information: your credit card details",
    "text": "3. Enter Billing Information: your credit card details\nNow you are asked for your credit card details. Note that your credit card will be verified once you click on the orange button Verify and Continue (step 3 of 5) and that you must select/provide the address associated with your credit card.\nPlease note the Secure verification message on the left: AWS will make a small charge (equivalent to $1 USD) on your card to verify it and the charge will appear in your card account as a pending transaction that will not be confirmed by AWS, and hence it will not be charged and will disappear from your account in 3-5 days.\n\n\n\n.\n\n\nAs part of the card verification process, a pop-up window from your bank or financial institution may appear and ask you to verify the AWS transaction. Choose the (Mobile or Home) phone registered with your card to receive the passcode, click on Confirm, and once you receive the passcode enter it as required.\n\n\n\n.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html#confirm-your-identity-to-aws-through-a-phone-call-or-sms-message",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html#confirm-your-identity-to-aws-through-a-phone-call-or-sms-message",
    "title": "Create Your AWS Account",
    "section": "4. Confirm your identity to AWS through a phone call or SMS message",
    "text": "4. Confirm your identity to AWS through a phone call or SMS message\nYou now need to confirm your identity to AWS through an SMS message or a phone call to the phone number that will be associated with your AWS account (we used the same phone number we entered in step 2).\nPlease select SMS message or phone call, enter your phone number and the characters in the security check box, and finally click on Send SMS (step 4 of 5). After you enter the code, you will receive the SMS or a phone call within a few seconds.\n\n\n\n.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html#select-support-plan-basic-and-complete-sign-up",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html#select-support-plan-basic-and-complete-sign-up",
    "title": "Create Your AWS Account",
    "section": "5. Select support plan (Basic) and complete sign-up",
    "text": "5. Select support plan (Basic) and complete sign-up\nYou must now select a support plan. Select the Basic support - Free plan and click on Complete sign-up. The Basic support plan is free and you don’t need more if this is your first AWS account.\n\n\n\n.\n\n\nThe congratulations page will then be displayed.\nYou will also receive three emails from AWS with the Subjects:\n\n“Welcome to Amazon Web Services”\n“AWS Support (Basic) Sign-Up Confirmation”\n“Your AWS Account is Ready - Get Started Now”\n\nThese emails have links to useful information and resources.\n\n\n\n.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/01-create-aws-account.html#login-to-your-aws-account",
    "href": "docs/lesson01-setting-work-envs/01-create-aws-account.html#login-to-your-aws-account",
    "title": "Create Your AWS Account",
    "section": "6. Login to your AWS account",
    "text": "6. Login to your AWS account\nFrom the congratulations page click on Go to the AWS Management Console where you will be able to sign in.\nLogin to your Root user account by entering the email address that you used to open your account in step 1 and click on the Next button.\n\n\n\n.\n\n\nYou will then be prompted to:\n\nEnter some characters by a “Security check” box and then your password\nSelect either the previous or the new version of the Console Home (please choose the new version)\nSelect your cookie preferences (select as you prefer).\n\n\n\n\n\n\n\nTypes of user\n\n\n\n\nThe login page gives the option to login either as the Root user or as an IAM user — IAM stands for Identity Access Managment.\nThe Root user account is for the owner of the account who “performs tasks requiring unrestricted access”, such as updating billing information or deleting the account, while an IAM user account is for a user who “performs daily tasks” such as using AWS services.\nAt this stage you can only login to the Root user account. In the next episode you will create an IAM account which you will use to create and manage AWS resources.\n\n\n\nFinally you will be logged in as Root user to the Console Home screen shown below, able to use your account. We will first configure your account in the next episode.\n\n\n\n.\n\n\nAs you eventually will logout from your account, please make a note of the address to log back in to the AWS Managment Console: aws.amazon.com/console or https://aws.amazon.com/console.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Create Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html",
    "href": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html",
    "title": "Configure Your AWS CloudShell Environment",
    "section": "",
    "text": "Prerequisites\n\n\n\nPlease read Workshops Organisation if you haven’t done so. To complete this episode you will need:\n\nif you are self-studying the course or attending a workshop using your AWS account:\n\nto have created and configured your AWS account as described in the two previous episodes: Create Your AWS Account and Configure Your AWS Account.\nthe login page, username and password of your IAM user account.\n\nif you are attending a workshop using a Cloud-SPAN AWS account (and an AWS Linux instance), you don’t need to complete this episode but to follow the instructions in the episode Configure Your Terminal Environment.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS CloudShell Environment"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html#login-to-the-aws-console",
    "href": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html#login-to-the-aws-console",
    "title": "Configure Your AWS CloudShell Environment",
    "section": "Login to the AWS Console",
    "text": "Login to the AWS Console\nTo access the AWS CloudShell environment and download the Scripts therein, you need to be logged in to the AWS Console with your IAM user account.\nOpen a new browser window and enter the address of the login page for your account IAM users. The address contains the account alias or your 12-digit account number:\n\nhttps://youraccountalias.signin.aws.amazon.com/console\nhttps://123456789012.signin.aws.amazon.com/console\n\nEnter your IAM username and password. You may also get a Security check to complete.\nOnce you are logged in, a page like the one below will appear.\nIMPORTANT: On the top right, check that the region is set to Ireland. Set it to Ireland if it is not:\nAn AWS CloudShell that you launch can only operate on resources within a selected region. Since the Cloud-SPAN Amazon Machine Image (AMI) from which you will create AWS instances with the Scripts is located in the Ireland region, you need to select this region before launching the AWS CloudShell.\nIf you are using an institutional account and you cannot set the region to Ireland, set it to the region which your institutional account is enabled to. Hence you will be installing and running the Scripts in the CloudShell for that region. However, before running the Scripts (in the next lesson), you will need to ask your IT department to copy the Cloud-SPAN AMI to your AWS account.\n(Note: you can launch multiple AWS CloudShells, each operating on a different region, but this is not needed and hence not covered in the course.)",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS CloudShell Environment"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html#launch-the-aws-cloudshell",
    "href": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html#launch-the-aws-cloudshell",
    "title": "Configure Your AWS CloudShell Environment",
    "section": "Launch the AWS CloudShell",
    "text": "Launch the AWS CloudShell\nTo launch the AWS CloudShell, click on its icon at the top: the little square with these two characters “**&gt;_**” inside.\n\n\n\n.\n\n\nYou will be presented with the message “Welcome to AWS CloudShell” below.\nIf you would like to learn more about the AWS CloudShell (software available, installing software, etc.), click on Learn more. A new browser tab will be opened with the online documentation about the AWS CloudShell.\nClick on Close to get to the AWS CloudShell.\n\n\n\n.\n\n\nYou will now be presented with the AWS CloudShell terminal, like the one below.\nIt may take up to a couple of minutes for the AWS CloudShell terminal to be ready the first time you open it in a Console session:\n\nfirst, an AWS instance called the environment will be launched — you will see the message “Waiting for the environment to run …”, not shown below\nthen the terminal program will be run — you will see the message “Preparing your terminal …”.\nfinally, you will see the terminal prompt, something like this: [cloudshell-user @ip-11-22-33-44 ~]$ — the numbers in the prompt are the IP address of the instance and may differ every time you open the AWS CloudShell.\n\nThe message after the first prompt, “Try these commands to get started: aws help …”, means that the AWS CLI, whose name when used is aws, is ready to be used.\n\n\n\n.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS CloudShell Environment"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html#download-the-scripts",
    "href": "docs/lesson01-setting-work-envs/04-configure-cloudshell.html#download-the-scripts",
    "title": "Configure Your AWS CloudShell Environment",
    "section": "Download the Scripts",
    "text": "Download the Scripts\nTo download the Scripts, enter or copy-paste the git command below into the terminal and press Enter.\n\n\nCode\n\ngit clone https://github.com/Cloud-SPAN/aws-instances.git ~/_tmp_cloudspan_aws\n\nNow enter the command ls -a ~ to list all the files (visible and hidden) in your home directory which is represented by the ~ character:\n\n\nCode\n\nls -a ~\n\nThe terminal should now look similar to the following. If so, you have downloaded the Scripts into the **_tmp_cloudspan_aws** directory in your home directory.\n\n\n\n.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS CloudShell Environment"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/02-configure-account.html",
    "href": "docs/lesson01-setting-work-envs/02-configure-account.html",
    "title": "Configure Your AWS Account",
    "section": "",
    "text": "Prerequisites\n\n\n\nPlease read Workshops Organisation if you haven’t done so. To complete this episode you will need:\n\nif you are self-studying the course or attending a workshop using your AWS account:\n\nto have opened your AWS account as described in the first episode of this lesson: Create Your AWS Account.\nto be logged in to your AWS account as the Root User (described also in that episode, at the end).\nideally, your mobile phone to add multi-factor authentication (MFA) to your AWS account. However, if you don’t have a mobile phone, you can skip this step and still use your AWS account.\n\nif you are attending a workshop using a Cloud-SPAN AWS account (and and AWS Linux instance), you don’t need to complete this episode.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/02-configure-account.html#introduction",
    "href": "docs/lesson01-setting-work-envs/02-configure-account.html#introduction",
    "title": "Configure Your AWS Account",
    "section": "Introduction",
    "text": "Introduction\nThese are the main steps you will follow to configure your AWS account:\n\nChange the default region of your account to Ireland.\nAWS services are provided through many regions around the world and a region is allocated by default. You will need to change the region of your account to Ireland because the Amazon Machine Image from which you will create your AWS instance is stored in the Ireland region. But you can later change your account region if you wish.\nSecure your AWS Root User account.\nThe account your created in the last episode is your Root user account and can perform any operation including closing the account. It is best practice to use the Root user account only for high-level administration and to create the first IAM (Identity Access Managment) user account for day-to-day work and account management. It is also best practice to secure the Root user account with multi-factor authentication (MFA).\nCreate an IAM user account to create and manage AWS resources.\nIAM user accounts are attached to a User Group that has a set of specific permissions (such as reading, writing and deleting) on specified resources. We will create a User Group with predefined permissions and an IAM user account in that group.\nCreate an alias for your account id.\nYour Root user account id is a 12-digit number that is difficult to remember. We are going to create an alias that is easier to remember. This is especially useful because the alias will replace the 12-digit number in the web address for logging in to your account as IAM user.\nGrant your IAM user account the permissions to access the Billing Dashboard.\nThe Billing Dashboard of your account is only accessible to the Root user by default. As you will mostly be using your IAM user account, it is convenient that you can check your bills and related information with your IAM user account too. We are going set on the permissions that enable your IAM user account to access the Billing Dashboard.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/02-configure-account.html#change-the-default-region-of-your-account-to-ireland",
    "href": "docs/lesson01-setting-work-envs/02-configure-account.html#change-the-default-region-of-your-account-to-ireland",
    "title": "Configure Your AWS Account",
    "section": "1. Change the default region of your account to Ireland",
    "text": "1. Change the default region of your account to Ireland\nOnce you have logged to your AWS Root user account, your browser will display a page showing the default region in the top right. This may be N. Virginia or another default.\nChange the region to Ireland: click on the region name that is shown and in the drop-down menu that pops up, select Europe (Ireland) eu-west-1.\n\n\n\n.\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can change the region any time you need.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/02-configure-account.html#secure-your-aws-root-user-account",
    "href": "docs/lesson01-setting-work-envs/02-configure-account.html#secure-your-aws-root-user-account",
    "title": "Configure Your AWS Account",
    "section": "2. Secure your AWS Root user account",
    "text": "2. Secure your AWS Root user account\nWe now are going to add multi-factor authentication (MFA) to your Root user account as an extra security mechanism. This requires you to download an app to your mobile phone, as described below.\n\n\n\n\n\n\nNote\n\n\n\nNo mobile phone?\nIf you don’t have a mobile phone, don’t worry, you can skip this step and go straight to step 3.\nIf you are not using MFA it is best to use your AWS Root user account only from your personal computer or a trusted computer.\n\n\nType iam in the AWS search box at the top and press Enter.\n\n\n\n.\n\n\nYou will be presented with the “IAM Dashboard”. Click on Add MFA.\n\n\n\n.\n\n\nOn the page that appears, “Your Security Credentials”, click Activate MFA.\n\n\n\n.\n\n\nA pop-up window called “Manage MFA device” will appear. Select Virtual MFA device and Continue.\n\n\n\n.\n\n\nYou will now be presented with a pop-up windows called “Set up a virtual MFA device”. Do not select anything at the moment.\n\n\n\n.\n\n\nTo set up your mobile as MFA device you will need a Virtual MFA app on your mobile phone. We have tested both “Duo Mobile” and “Google Authenticator” and give instructions for both but you may already be using another app. AWS lists some options here: AWS MFAs.\nIf you do not have a Virtual MFA app on your mobile phone: Go to the app store on your phone, search for Duo Mobile or Google Authenticator, and install it.\nOnce you have installed an MFA app in your mobile: - Return to the above pop-up “Set up a virtual MFA device” on your computer and choose Show QR code. - Open the MFA app on your phone - Press + Add in Duo Mobile or + in Google Authenticator - Press Use QR code in Duo Mobile or Scan a QR code in Google Authenticator. Your camera will open to scan a QR code. - Point your camera at your computer screen showing the QR code to scan. You may need to adjust the zoom for the scan to occur. - Once the scan is successful, the MFA app will display a number for about 30 seconds, and then another number for the same time, and so on until you close the app. - Of those numbers shown in your mobile MFA, you need to enter two consecutive numbers into the fields MFA Code 1 and MFA Code 2 on the last pop-up window “Set up a virtual MFA device” on your computer. You may need to scroll down to see MFA Code 2. NB: enter the numbers with no space between them even if they are shown with a space in your mobile. - Click on Assign MFA.\nYou will see a success message which you can close.\nEvery time you login to your Root user account, you will be asked to enter your password and an MFA code number which you must read from your mobile by simply opening the MFA app.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/02-configure-account.html#create-an-iam-user-account-to-create-and-manage-aws-resources",
    "href": "docs/lesson01-setting-work-envs/02-configure-account.html#create-an-iam-user-account-to-create-and-manage-aws-resources",
    "title": "Configure Your AWS Account",
    "section": "3. Create an IAM user account to create and manage AWS resources",
    "text": "3. Create an IAM user account to create and manage AWS resources\nWe are going to create an IAM user account with which you will be able to create and manage AWS resources. This involves first creating an IAM User Group with one or more security policies, and then your IAM user account within that User Group.\nWe will create a user group called Administrators, then a user account called YourName (your actual name), and finally attach the account to the group. As this is the first IAM group and IAM account to be created, we need to do this with the Root user account, but then it will be possible to do it with the IAM account we will create because it will have Administrator privileges.\n\nCreate the user group\nGo to the IAM Dashboard page by typing iam in the AWS search box at the top and pressing Enter. On the IAM Dashboard, click on “User groups” under “Access Management” on the left, and then on Create group on the right.\n\n\n\n.\n\n\nIn the page that appears, “Create user group”, type “Administrators” in the box “User group name” but don’t press Enter yet.\n\n\n\n.\n\n\nScroll down until you see the section “Attach permissions policy - Optional”. This section has a search box and a list of different policies.\nType “administratoraccess” in the search box and press Enter.\n\n\n\n.\n\n\nThis will bring the “AdministratorAccess” policy to the top of the list. Check the box next to that policy and then click on Create group.\n\n\n\n.\n\n\nThe screen displayed after creating the group may indicate it is loading users — it’s OK, ignore it.\nYou now have a user group called Administrators\n\n\n\n.\n\n\n\n\nCreate your IAM user account and add it to the Administrators group\nTo create your IAM user account, click on Users in the last page displayed in the previous step, on the left in the figure above.\nThe page titled “Users” will be displayed. Click on Add users.\n\n\n\n.\n\n\nThe page below will be displayed, where you can enter your IAM user account details by: - typing your user name (a single word of your choice) - checking the box “Access Key - Programmatic access” — this option enables you to use the AWS CLI - checking the box “Password - AWS Management Console access” - checking the box “Autogenerated password” and - checking the box “User must create a new password at next sign-in”\nThen click on Next: Permissions\n \nYou will be presented with a page that says “Add user - Set permissions”. The Add user to group option should be set (in blue). Leave it set — if it is not set, click on it to set it.\nCheck the box next to the group Administrators and then click on Next: Tags.\n\n\n\n.\n\n\nYou will be presented with a page that says “Add user - Add tags (optional)”, not shown here as we are not adding tags. Click on the button Next: Review.\n\n\n\n\n\n\nNote\n\n\n\nNote on tags\nAdding tags — or keywords — to an AWS resource is optional. You don’t need to tag your IAM user account because you only have one such account. Adding tags is useful when you are managing multiple user accounts/resources as it helps searching for specific resources based on their tags.\n\n\nYour will now be presented with a page displaying the options chosen for your IAM user account for review. If these are correct click on Create user.\n\n\n\n.\n\n\nYou will now see a page with the message Success — You successfully created the users shown below…\nYou need to download the .csv file indicated in this page by clicking on Download .csv. This file contains the credentials both to login to the AWS Console and to access AWS resources programmatically with your new IAM user account. Programmatically means access from software applications including the AWS CLI.\nFor security reasons you will not be able to access these credentials once you leave this page but you can create new credentials.\nClick on Download .csv to download and save the file in your computer.\n\n\n\n.\n\n\n\n\n\n\n\n\nWhat’s in the file?\n\n\n\nThe file you downloaded is a comma separated value (CSV) file that you can open in any text editor. Its content is something like this:\nUser name,Password,Access key ID,Secret access key,Console login link adminuser,0ji)8[bN3{F-X!h,BMZ4AD..KIAVQN34,o0/bSO3WJeO..Vgtc4E3LxXZVbQg,https://xxxxxxxxxxxx.signin.aws.amazon.com/console\nThe first line specifies the names of the comma-separated values in the second line — comma characters are not part of any of the values.\nThe values in the second line shown above will be different to those in your CSV file.\nThe first and second fields, adminuser and 0ji)8[bN3{F-X!h are the username and the password to access the AWS Console. The third and the fourth fields, BMZ4AD..KIAVQN34 and o0/bSO3WJeO..Vgtc4E3LxXZVbQg, are the access key ID and the secret access key which, combined, will enable you to use the AWS CLI and, more generally, to access AWS resources programmatically. The last field, https://xxxxxxxxxxxx.signin.aws.amazon.com/console, is the web address to login to the AWS Console with the IAM user account you have created, and other IAM accounts you may create later.\nNB: the first time you login to the AWS Console you will have to change the password.\nNB: we are representing here with “xxxxxxxxxxxx” the digits in the URL to login to the AWS Console, https://xxxxxxxxxxxx.signin.aws.amazon.com/console. This 12-digit number corresponds to your account id.\n\n\nOnce you close the success message above, in the page that appears you should see the user account you have just created, listed along with the Groups (Administrators) of which it is a member and other information, for example: “Never” under “Last activity” means you have not yet logged in.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/02-configure-account.html#create-an-alias-for-your-iam-user-acount",
    "href": "docs/lesson01-setting-work-envs/02-configure-account.html#create-an-alias-for-your-iam-user-acount",
    "title": "Configure Your AWS Account",
    "section": "4. Create an alias for your IAM user acount",
    "text": "4. Create an alias for your IAM user acount\nA 12-digit number can be difficult to remember so let’s create an alias which is easier to remember. The alias can be used to login to your account.\nType iam in the AWS search box and press Enter to go to the “IAM Dashboard”.\nOn the right of the Dashboard, under the heading “AWS Account”, click on Create next to “Account Alias”\n\n\n\n.\n\n\nNow enter the alias you want to use — which might be some version of your name or date of birth. Note the new sign-in URL. Click on Save changes.\n\n\n\n.\n\n\nYou can now login to your account using either web address: the one with your 12-digit account number or the one with your alias.\n\n\n\n\n\n\nAccess your IAM user account with both URLs:\n\n\n\n\nopen two new tabs in your browser (but do not close this browser tab so that we can finish up setting up your IAM account with the last step below).\nenter https://xxxxxxxxxxxx.signin.aws.amazon.com/console in one of the tabs, but change “xxx..xxx” with your 12-digit account number.\nenter https://youralias.signin.aws.amazon.com/console in the other tab, but change “youralias” with your actual account alias.\nin both tabs use your actual username and password from your .csv file.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS Account"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/02-configure-account.html#grant-your-iam-user-account-the-permissions-to-access-the-billing-dashboard",
    "href": "docs/lesson01-setting-work-envs/02-configure-account.html#grant-your-iam-user-account-the-permissions-to-access-the-billing-dashboard",
    "title": "Configure Your AWS Account",
    "section": "5. Grant your IAM user account the permissions to access the Billing Dashboard",
    "text": "5. Grant your IAM user account the permissions to access the Billing Dashboard\nTo grant your IAM user account the permissions to access the Billing Dashboard, go to the Account Settings page as follows:\n\non the navigation bar at the top, on the far right, click on your “account name” (or account number, if you did not setup an account alias), and\non the drop-down menu that pops up, click on Account\n\n\n\n\n.\n\n\nOn the page that appears:\n\nScroll down until you see the heading:\n\n        IAM User and Role Access to Billing Information\n\nTo the right of the heading, click on Edit.\nCheck Activate IAM Access.\nClick on Update.\n\nYou have now configured your AWS account for day-to-day use.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your AWS Account"
    ]
  },
  {
    "objectID": "docs/miscellanea/about.html",
    "href": "docs/miscellanea/about.html",
    "title": "About",
    "section": "",
    "text": "Cloud-SPAN is a collaboration between the University of York and The Software Sustainability Institute funded by the UKRI Innovation Scholars award. Project Reference: MR/V038680/1.\nCloud-SPAN trains researchers, and the research software engineers that support them, to run specialised analyses on cloud-based high-performance computing infrastructure. We are developing highly accessible resources which integrate with existing Carpentries courses.\nThis set of lessons is based on the Data Carpentries Genomics Workshop."
  },
  {
    "objectID": "docs/miscellanea/about.html#our-handbook",
    "href": "docs/miscellanea/about.html#our-handbook",
    "title": "About",
    "section": "Our Handbook",
    "text": "Our Handbook\nThe Cloud-SPAN team are dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. We hope aim to develop a community of practice around our materials. We have a Handbook that gives:\n⭐ An introduction to the Cloud-SPAN project\n🤝 Our Code of Conduct\n🎓 More information on our Courses\n👪 An open invitation to the Cloud-SPAN Community\n📌 Information about the FAIR Principles\n📜 Cloud-SPAN Online Forum"
  },
  {
    "objectID": "docs/miscellanea/about.html#licences",
    "href": "docs/miscellanea/about.html#licences",
    "title": "About",
    "section": "Licences",
    "text": "Licences\nThis instructional material is made available under the [Creative Commons Attribution license][cc-by-human]. The following is a human-readable summary of (and not a substitute for) the [full legal text of the CC BY 4.0 license][cc-by-legal].\nThe Cloud-SPAN Genomics course consists of materials derived from Data Carpentry’s Genomics Workshop. This material is not endorsed by Data Carpentry or the Carpentries in general.\nCloud-SPAN is a collaboration between the University of York and The Software Sustainability Institute funded by the UKRI Innovation Scholars award. Project Reference: MR/V038680/1."
  },
  {
    "objectID": "docs/miscellanea/precourse-instructions.html",
    "href": "docs/miscellanea/precourse-instructions.html",
    "title": "Precourse Instructions",
    "section": "",
    "text": "To take the course Automated Management of AWS Instances you are expected to:\n\ninstall Git Bash — Windows users\ninstall or update Bash — Mac users\nuse a laptop or desktop computer with access to the Internet and a browser (such as Chrome) installed\n\nThis Setup section provides instructions to install Git Bash on Windows computers and to install or update Bash in Mac computers.\n\nIntroduction\nThe course teaches how to use a set of Bash scripts to manage (create, configure, stop, start and delete) one or multiple AWS instances with a single invocation of a script.\nTo run the scripts you need to use a terminal that runs the Bash shell. The terminal is a program that enables you to enter textual commands through the keyboard to instruct the operating sytem in your computer the operations you want to be performed such as running a program or copying or deleting files. The terminal is also widely known as the shell and the command-line interface (CLI). In this course we mostly use the term “terminal” and occasionally “shell” and “command line” where more meaningful. Bash stands for Bourne Again Shell. It is a powerful command programming language that was developed to serve as the CLI for the UNIX operating system. Bash is currently the most widely used shell and has a long and interesting history which you can read in the Wikipedia entry for Bash shell.\nLinux users don’t need to install any software as the terminal in Linux systems runs Bash by default.\nWindows users will need to install Git for Windows on their computer as described below prior to the course. Git for Windows includes Git Bash, a Windows version of the Unix Bash shell, ssh (secure shell) and many other useful programs. ssh is used to login to the AWS instances created with the scripts.\nMac users will need to install or update Bash on their computer as described below. Mac computers usually have installed both the Zsh shell and the Bash shell; and the terminal runs Zsh by default. Zsh and the Bash version usually installed (3.2.57 or so) cannot run the scripts that manage AWS instances. Hence you need to update Bash (the version we updated to in early 2023 was 5.2.15). Note that you can “run” the scripts from a terminal that runs Zsh, but as the first line of each script is this #!/usr/bin/env bash, a Zsh terminal will run Bash to actually run each script.\n\n\n\n\n\n\nInstall Git Bash (Git for Windows) — Windows users\n\n\n\n\n\nThe steps below correspond to the installation of Git for Windows version 2.33.1 from scratch. The installation of a more recent version, or updating a previously installed version, may show different wording in the screen messages mentioned below or may vary slightly in the number of steps to follow. Choose as many of the options below as possible.\n\nClick on this link: Git for Windows download page\nOnce in that page, click on Download to download the installer.\nOnce the installer is downloaded,\n\ndouble click on it\nyou will then be asked some questions and to select an option for each question.\neach question is shown below in Italics, and the selection to be made is shown in bold\n\nThe app you’re trying to install isn’t a Microsoft-verified app ..?\n\nClick on Install anyway\n\nDo you want to allow this app to make changes to your device?\n\nClick on Yes\n\nGNU General Public License\n\nclick on Next\n\nSelect Destination Location\n\nclick on Next (don’t change the location shown).\n\nSelect Components\n\nclick on Additional Icons (it will also select “On the Desktop” option)\nthen click on Next\n\nSelect Start Menu Folder\n\nclick on Next (don’t change the folder name shown)\n\nChoosing the default editor used by Git\nselect Use the nano editor by default and click on Next.\nNB: you may need to click on the dropdown menu and to scroll up with the mouse to see this option – see the figure:\n\n\n\n\n.\n\n\n\nAdjusting the name of the initial branch in new repositories\n\nkeep the selected (or select the) option Let Git decide and click on Next.\n\nAdjusting your PATH environment\n\nkeep the selected, Recommended option Git from the command line and also from 3rd-party software\nor select it, and click on Next.\nNB: if this option is not selected, some programs that you need for the course will not work properly. If this happens rerun the installer and select the appropriate option.\n\nChoosing the SSH executable\n\nkeep the selected (or select the) option Use bundled OpenSSH and click on Next.\n\nChoosing HTTPS transport backend\n\nkeep the selected (or select the) option Use the OpenSSL library and click on Next.\n\nConfiguring the line ending conversions\n\nkeep the selected (or select the) option Checkout Windows-style, commit Unix-style line endings and click on Next.\n\nConfiguring the terminal emulator to use with Git Bash\n\nkeep the selected (or select the) option Use MinTTy (the default terminal of MSYS2) and click on Next.\n\nChoose the default behaviour of git pull\n\nkeep the selected (or select the) option Default (fast-forward or merge) and click on Next.\n\nChoose a credential helper\n\nkeep the selected (or select the) option Git Credential Manager Core and click on Next.\n\nConfiguring extra options\n\nkeep the selected option (Enable File System Caching) and click on Next.\n\nConfiguring experimental options\n\nclick on Install without selecting any option\n\nClick on Finish\n\nRun Git Bash by double clicking on the Git Bash icon in your Desktop screen.\n\n\n\n.\n\n\nExit Git Bash by pressing the keys Ctrl and d (Ctrl-d) simultaneously.\n\n\n\n\n\n\n\n\n\nInstall or update Bash — Mac users\n\n\n\n\n\nTo install or update Bash, open a terminal and enter the brew command in the code box below. You can copy-paste the command but don’t include the dollar sign $.\n\n\nCode\n\n $ brew install bash\n\nYou will see an output like the following:\n\n\nOutput\n\n Running `brew update --auto-update`...\n ==&gt; Downloading https://formulae.brew.sh/api/formula.jws.json\n ######################################################################## 100.0%\n ==&gt; Downloading https://formulae.brew.sh/api/cask.jws.json\n ######################################################################## 100.0%\n ==&gt; Auto-updated Homebrew!\n Updated 1 tap (aws/aws).\n\n ==&gt; Fetching bash\n ==&gt; Downloading https://ghcr.io/v2/homebrew/core/bash/manifests/5.2.15\n ######################################################################## 100.0%\n ==&gt; Downloading https://ghcr.io/v2/homebrew/core/bash/blobs/&gt; sha256:05a5f9435c9e9ffe8377b03e0ca6b27bbb32cc\n ==&gt; Downloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/&gt; sha256:05a5f9435c9e9ffe8377\n ######################################################################## 100.0%\n ==&gt; Pouring bash--5.2.15.monterey.bottle.tar.gz\n 🍺  /usr/local/Cellar/bash/5.2.15: 162 files, 11.7MB\n ==&gt; Running `brew cleanup bash`...\n Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n\nCheck the Bash version installed with the command:\n\n\nCode\n\n $ bash --version\n\nIf the package manager brew is not installed in your computer, you can install it with the command below (from the brew website):\n\n\nCode\n\n $ /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/03-configure-terminal.html",
    "href": "docs/lesson01-setting-work-envs/03-configure-terminal.html",
    "title": "Configure Your Terminal Environment",
    "section": "",
    "text": "Prerequisites\n\n\n\nPlease read Workshops Organisation if you haven’t done so. To complete this episode you will need:\n\nif you are self-studying the course or attending a workshop using your AWS account:\n\nto have created and configured your AWS account as described in the two previous episodes: Create Your AWS Account and Configure Your AWS Account.\nyour AWS account programmatic access credentials (*):\n\nAccess Key ID\nSecret Access Key\n\nWindows users: to have installed Git Bash — see the Setup section.\nMac users: to have installed or updated Bash — see the Setup section.\nMac and Linux users: to have installed: git, curl, unzip, ssh\n\nif you are attending a workshop using a Cloud-SPAN AWS account (and an AWS Linux instance):\n\nto follow the instructions in this episode for Linux terminals.\nWindows users: to have installed Git Bash — see Workshops Organisation and the Setup section.\n\n\n(*) Those credentials are in the .csv file you downloaded once you created your IAM account as part of configuring your AWS account.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your Terminal Environment"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/03-configure-terminal.html#download-the-scripts-from-github",
    "href": "docs/lesson01-setting-work-envs/03-configure-terminal.html#download-the-scripts-from-github",
    "title": "Configure Your Terminal Environment",
    "section": "Download the Scripts from GitHub",
    "text": "Download the Scripts from GitHub\nTo download the Scripts, open your (Git Bash, Linux or Mac) terminal and enter or copy-paste the git command below:\n\n\nCode\n\ngit clone https://github.com/Cloud-SPAN/aws-instances.git  ~/_tmp_cloudspan_aws",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your Terminal Environment"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/03-configure-terminal.html#make-the-scripts-accessible-through-the-execution-path",
    "href": "docs/lesson01-setting-work-envs/03-configure-terminal.html#make-the-scripts-accessible-through-the-execution-path",
    "title": "Configure Your Terminal Environment",
    "section": "Make the Scripts accessible through the execution path",
    "text": "Make the Scripts accessible through the execution path\nThere are many ways to make the Scripts accessible through the execution path. To avoid any conflicts with the current configuration of your Linux machine, we are going to:\n\ncreate a new “bin” directory\ncopy the Scripts to the new bin directory\nadd the new bin directory to the execution path\n\nYou can copy-paste the commands below to carry out those three steps using ~/.local/bincsaws as the new bin directory, but note:\nIf ~/.local/bincsaws already exists in your environment (which you can check with the command ls ~/.local), choose another name for bincsaws and use the new name instead of bincsaws in the three commands below:\nClick the bar that corresponds to your terminal to display the next command you will type or copy-paste into your terminal:\n\n\n\n\n\n\nGit Bash and Linux terminal\n\n\n\n\n\n\n\nCode\n\necho \"PATH=\\\"\\$HOME/.local/bincsaws:\\$PATH\\\"\" &gt;&gt; ~/.bashrc\n\n\n\n\n\n\n\n\n\n\nMac terminal that runs Bash:\n\n\n\n\n\n\n\nCode\n\necho \"PATH=\\\"\\$HOME/.local/bincsaws:\\$PATH\\\"\" &gt;&gt; ~/.bash_profile\n\n\n\n\n\n\n\n\n\n\nMac terminal that runs Zsh shell:\n\n\n\n\n\n\n\nCode\n\necho \"PATH=\\\"\\$HOME/.local/bincsaws:\\$PATH\\\"\" &gt;&gt; ~/.zshrc\n\n\n\n\nThe last command echo \"PATH=\\\"\\$HOME ... adds an assignment shell statement at the end of your terminal shell configuration file (either ~/.bashrc or ~/.bash_profile or ~/.zshrc depending on your terminal).\nThe statement adds the new bin directory to the execution path which is held by the shell variable PATH.\nSince the terminal runs the commands in that configuration file every time it is launched, that is, every time your login to your instance, the assigment shell statement (we added) will add the “new” bin directory to the execution path on every subsequent launch of the terminal, thus making the Scripts accessible from any directory location.\nYou need to open (launch) a new terminal for the execution path to get updated (you can close the old terminal as you won’t use it anymore).\nOnce you have opened a new terminal, the Scripts will be accessible through the execution path and you should be able to run the command csinstances_create.sh as shown below. This script is one of the Scripts installed in ~/.local/bincsaws.\n\n\nCode\n\n$ csinstances_create.sh\n\nThe output of csinstances_create.sh in your terminal should look like this:\n\n\n\n.\n\n\nThe script csinstances_create.sh was found and run, but as it requires a parameter (the name of a file), it only displayed the usage message and finished.\n\n\n\n\n\n\nDon’t delete the directory ~/_tmp_cloudspan_aws where the Scripts were downloaded\n\n\n\nPlease don’t delete that directory just yet. We will use some files there in in the next lesson. Once we use those files you can delete that directory.",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments",
      "Configure Your Terminal Environment"
    ]
  },
  {
    "objectID": "docs/lesson01-setting-work-envs/index.html",
    "href": "docs/lesson01-setting-work-envs/index.html",
    "title": "Setting Up Your Cloud and Terminal Environments",
    "section": "",
    "text": "Please read Workshops Organisation if you haven’t done so.\nThe Bash shell scripts that automatically manage multiple AWS instances will be referred to as the “Scripts” from now on.\nYou can use any of the following terminals to run the Scripts as instructed in this course:\n\nLinux terminals that run the Bash shell.\nWindows Git Bash terminals — see the Setup section.\nMac terminals that run the Bash shell or the Zsh shell — see the Setup section to install or update Bash; Bash version must be 5.0 or higher.\nthe AWS CloudShell terminal, a Linux terminal that runs the Bash shell by default. The AWS CloudShell is hosted on AWS and is used through the browser.\n\n\nOverview\nThe Scripts make use of the AWS Command Line Interface (AWS CLI), a software tool that enables you to interact with AWS through commands that can be run either within shell scripts or in any of those terminals above (and others). The Scripts run the AWS CLI to make requests to manage (create, allocate, …, and delete) AWS services such as instances, storage, domain names, etc. For such requests to be successful, the AWS CLI and the target AWS account, wherein services will be managed, need to be configured.\nThis lesson will guide you to: - create your AWS account. - configure your AWS account for daily work, including enabling access with the AWS CLI. - configure your terminal environment with the Scripts and the AWS CLI, the AWS CLI configured to manage resources within your AWS account.\n\nYour AWS account\nEpisodes 1 and 2 provide the instructions to create and configure your AWS account.\nWe organised the instructions in all episodes (4 episodes in lesson 1 and 4 in lesson 2) assuming that you are going to create and use your own AWS account, and hence you have full permissions to configure it as instructed in the course — we refer to such an account as an AWS personal account.\nHowever, you can use an existing AWS account you have access to. Throughout the course, where relevant, we point out what “extra steps” you may need to do to configure your account as required to run the Scripts.\nIf you already have an AWS account that you would like to use to run the Scripts, skip Episode 1 and configure your account as described in Episode 2. Specifically, to enable access with the AWS CLI, you need to have/create an IAM (Identity and Access Management) user account enabled with programmatic access based on Access key ID and Secret access key credentials. If the AWS account you are using is your personal account, you have full permissions to do the configuration presented in that section.\nIf the AWS account that you would like to use to run the Scripts is an institutional account, meaning that it was provided to you by your institution (company, school, organisation), skip Episode 1 and configure your account with programmatic access as mentioned above, if possible. However, you may need to contact your IT department to help you configure your account as required to run Scripts. Typically, institutional accounts are created and somewhat configured by the IT department of the institution first, and only then passed to a person for that person’s individual use. The configuration by an IT department may include using AWS services in a single region only (in USA, Europe, etc.), or accessing AWS services using specific security applications, among other regulations, see the callout below.\n\n\n\n\n\n\nAre you using an institutional AWS account?\n\n\n\nIf you are using an institutional account, you are very likely to be using specific security applications to access your account. For instance:\n\nto access the AWS Console with our institutional AWS account, we use the applications Shibboleth and Duo Mobile. Shibboleth runs in the browser to ask for our username, password, and a pushed notification from Duo Mobile in our mobile phone.\nto access AWS services through the AWS CLI, invoked either from a script or from our terminal (environment), we first need to run the application saml2aws to generate a token that is valid for 1 hour, and run it again as needed.\n\nThe course does not cover the configuration and use of those or similar security applications which may be used in your institution. Your IT department will be able to help you.\nNote that, using our institutional account, we have successfully run the Scripts to access AWS services through the AWS CLI using either saml2aws or the keys credentials mentioned above, which we created in the AWS Console. Thus our institutional account, as configured by our IT department, enables access through both saml2aws and keys credentials. Only the creation and use of keys credentials is presented in Episodes 2 and 3.\n\n\n\n\nYour terminal environment\nEpisode 3 provides the instructions to install the Scripts and the AWS CLI in your Git Bash, Linux or Mac terminal environment, and to configure the AWS CLI to use your credentials (private and public keys) when invoked within the Scripts to request AWS service operations. The credentials will be generated using the AWS Console when you configure your AWS account in Episode 2.\nEpisode 4 provides the instructions to configure the Scripts in the AWS CloudShell. The AWS CloudShell is “a browser-based [Linux Bash terminal] shell that gives you command-line access to your AWS resources” and has the AWS CLI already installed and ready to run using “credentials” derived from the information you use to login to the AWS Console. Hence you only need to configure the Scripts, but you must be logged in to your AWS account through the AWS Console to be able to run the AWS CloudShell and the Scripts.\nIn this course you will be using the AWS Console and, through the Scripts, the AWS CLI to manage AWS services but there are other ways to manage AWS services, see the callout below.\n\n\n\n\n\n\nWays to access and manage AWS services\n\n\n\nThere are four ways to access and manage AWS services:\n\nthe AWS Console, a browser-based graphical user interface (GUI)\nsoftware development kits (SDKs or libraries) for use with programming languages such as Python, JavaScript, Java, etc.\nthe AWS CLI\ninfrastructure as code (IaC) blueprints, which are textual descriptions of cloud resources and their dependencies.\n\nThe AWS Console is mostly used to open an AWS account, to do one-off configurations, and to browse the overall state of resources used by an account. Periodic, frequent or many interactions with AWS services are better managed through the other three options.\nSDKs are mostly used to develop browser- based and cloud-based applications for end users. The AWS CLI and IaC blueprints are typically used to manage resources under an admin role. The AWS CLI is probably the fastest way to get started because of familiarity: shell scripts have been used for decades in resource management.\nIaC blueprints are used with systems such as Terraform or AWS Cloud Formation. Basically, you write a blueprint of your infrastructure (service architecture) as code in a declarative language (that is: you specify “what you want”, as opposed to “how to do what you want”, which is typical of procedural languages, including the Bash shell). On “running” your blueprint, the services making up your infrastructure will be created, configured to some extent, and launched. If later you update your blueprint (say, delete or add more services), your infrastructure will be updated accordingly when you run your blueprint again. As blueprints are simple text files, you can use version control with Git and roll-back to a previous version of your system. The main issue with using IaC blueprints is the steep learning curve to get proficient in using the approach, the language and the target resources. IaC blueprints are suitable for managing systems that change often because of continuous improvements.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Setting Up Cloud/Terminal Environments"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/index.html",
    "href": "docs/lesson02-managing-aws-instances/index.html",
    "title": "Managing AWS Instances",
    "section": "",
    "text": "Please read Workshops Organisation if you haven’t done so.\nThe environments and configurations presented in the previous lesson, Setting Up Your Cloud and Terminal Environments, comprise a base development environment to create and manage AWS services with both the AWS Console and the AWS CLI (command line interface). If you are using an AWS personal account (that you created and configured as described in that lesson), you can create and manage any service in any AWS region, as your account was configured with the AdministratorAccess permissions policy which “Provides full access to AWS services and resources”.\nTowards using the Scripts to create and manage AWS instances, we will first need to configure Internet access for the instances. The instances configuration and the Scripts were designed for each instance to be accessed through a domain name and with the program ssh using an encrypted login key, as outlined below. Hence, we will create a base domain name from which the Scripts will create, for each instance, a subdomain name to identify and make each instance accessible with ssh. Creating a domain name in your AWS account will incur some cost, as low as US $5.00 per year or more depending on the suffix /top-level domain (TLD) that you choose for your base domain name. Examples of TLDs include: .com, .net, .org, .link, among many others (the cheapest in AWS is .link). If you already have a domain name in place, you can use that instead. Your account will also incur costs for any service you launch that is not included in the AWS Free Tier — check the lesson AWS Costs Explained from another Cloud-SPAN course, so you know your free limits.\nIf you are using an AWS institutional account (that was created and configured by the IT department in your institution), you will most likely not be directly responsible for the cost of using a domain name or any other service with your account. However, you may need to ask your IT department to configure a base domain name for you, or to follow some guidelines to specify the domain name. Your account may also have restrictions as to the AWS region where you can create and manage AWS services. For instance, the AWS institutionl account of the Cloud-SPAN project can only make use of services in the eu-west-1 Ireland region, and the Cloud-SPAN base domain name was suggested and configured by our IT department. If your institutional account is restricted to use an AWS region other than Ireland, you may need to ask your IT department to make a copy, to your AWS account, of the Amazon Machine Image (AMI) template used by the Scripts to create AWS instances. Your IT department should be able to help you with this and other matters; just let them know what you need to configure in your AWS account to use the Scripts, and whenever you come accross Access Denied or similar messages when using the Scripts.\n\nOverview\nWe use the Scripts to create and manage multiple AWS instances for training. When running a workshop, a number of instances is created as a copy of an AMI that is configured with ’omics data and software analysis tools that are relevant to the workshop. Each student is granted exclusive access to one instance.\nEach instance is created to be accessed through a domain name using ssh and an encrypted login key file.\nFor example, using the base domain name of the Cloud-SPAN project, cloud-span.aws.york.ac.uk, the (sub) domain name for an instance named instance001 would be instance001.cloud-span.aws.york.ac.uk.\nUsing the base domain name of an AWS personal account, for example, awsplaicloud.com, the domain name for the same instance name would be instance001.awsplaicloud.com.\nOnce an instance is created, the end user will access the instance csuser account with ssh providing the name of the corresponding login key file as shown below.\nUsing the AWS Cloud-SPAN institutional account base domain name:\n\n\nCode\n\n$ ssh -i login-key-instance001.pem  csuser@instance001.cloud-span.aws.york.ac.uk     ### -i stands for identity file\n\nUsing the personal account based domain name:\n\n\nCode\n\n$ ssh -i login-key-instance001.pem  csuser@instance001.awsplaicloud.com              \n\nEach instance domain name is mapped to an IP address. Domain names, IP addresses, and login keys are created automatically on creating the corresponding instances, and deleted likewise when the corresponding instances are deleted.\n\nEpisode 1: Configure Instances Internet Access\nEpisode 1 will guide you to configure internet access for the instances you will create with the Scripts. This involves: - creating a base domain name - creating a few access rules for the communication ports used by the ssh program - selecting an AWS network to which the instances will be attached so that they can be reached from anywhere with ssh\n ### Episode 2: Instances Management Tasks Using the Scripts\nEpisode 2 is the guide to using the Scripts to create and manage multiple instances for a course /workshop. The episode shows: - how to configure the Scripts with the names of the instances to create and the AWS resources to use (base domain name, AMI template, etc.). - how to organise the Scripts configuration files for multiple courses. - how to use /run the Scripts and manage unforseen instances management requests such as cancellations by workshop participants - some troubleshooting\n\n\nEpisode 3: AMIs Management\nEpisode 3 is about managing Amazon Machine Images (AMIs). As AWS instances are copies of an AMI, you need to create a new AMI if the software or data used in a course change, but there are other reasons that may require creating a new AMI. The episode presents the management of AMIs that we have done as part of managing AWS instances with the Scripts.\n\n\nEpisode 4: The Scripts Design\nEpisode 4 presents the organisation and workings of the Scripts, how the Scripts were developed using the AWS CLI Command Reference, and a few ideas to improve the Scripts.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Home",
      "Managing AWS Instances"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "",
    "text": "Prerequisites\n\n\n\nPlease read Workshops Organisation if you haven’t done so. To complete this episode you will need:\n\nif you are self-studying the course or attending a workshop using your AWS account:\n\nto have created your AWS account as described in Create Your AWS Account (Episode 1, Lesson 1).\nto have configured your AWS account as described in Configure Your AWS Account (Episodes 2, Lesson 1).\nto have configured your terminal environment as described in either of these episodes:\n\nConfigure Your Terminal Environment (Episode 3, Lesson 1) — or\nConfigure Your AWS CloudShell Environment (Episode 4, Lesson 1)\n\nto have configured instances internet access as described in Configure Instances Internet Access (previous episode, this lesson).\nyour base domain name.\nthe AWS resource IDs of your: host zone, security group, and subnet.\nthe AWS Console login details of your IAM user account: login page, username and password.\n\nif you are attending a workshop using a Cloud-SPAN AWS account (and an AWS Linux instance), you will be given the necessary information at the workshop.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#sections",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#sections",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Sections",
    "text": "Sections\n\nThe Scripts Running Environment\nThis section introduces the Scripts, the directory-file structure the Scripts require to run successfully, and the constraints you need to observe in configuring and running the Scripts.\nConfigure the Scripts Running Environment\nYou will create a running environment for the Scripts within your terminal environment: a Git Bash terminal, a Linux terminal, a Mac terminal or the AWS CloudShell terminal. You will create the directory-file structure that will enable the Scripts to manage a few AWS instances.\nCreate the Instances\nYou will create the instances specified in Section 2 and this will generate some results. The results generated and displayed to the terminal by the Scripts that create AWS resources (instances, login key files, etc.) will be explained to help you understand how the Scripts work.\nCheck Instances Are Accessible\nOnce instances are created, it is convenient to check that they are accessible through ssh by logging in to a few of them. This section will show you how to login to instances in a way easier than using ssh directly.\nUnderstand the Results of Creating Instances\nCreating AWS resources involves making AWS requests that return back results that are saved to files within the Scripts running environment. These files are crucial for the successful operation of the Scripts in stopping, starting and eventually deleting the created resources. These files are explained in this section to round up your understanding of how the Scripts work.\nTypical Instances Life Cycle: create, stop, start and delete instances\nThis section describes the typical use-case scenario of instances management for a workshop /course. It describes our approach to instances management using both the terminal and the AWS Console. This section also describes how to create instances in two steps in order to reduce costs when deploying relatively large instances in terms of storage.\nUnforeseen Instance Management\nThis section describes our approach to handle unforeseen instance management requests such as creating additional instances for a workshop due to late registrations, or deleting some (not all) instances before the end of a workshop due to cancellations.\nTroubleshooting\nThis section presents some problems we have come across in managing instances and how to solve them.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#creating-instances-one-or-more-days-before-a-workshop-starts",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#creating-instances-one-or-more-days-before-a-workshop-starts",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Creating instances one or more days before a workshop starts",
    "text": "Creating instances one or more days before a workshop starts\nOnly run csinstances_create.sh if you did not run it in the previous section!!!\n\n\nCode\n\ncsuser@cloud-admin-instance:~\n$ csinstances_create.sh courses/instances-management/inputs/instancesNames.txt \n\nOnce you have run csinstances_create.sh, the instances state in the AWS Console will be Running as shown below (you may need to refresh the page):\n\n\n\nScreenshot of AWS Console EC2 Instances page in a browser showing the state, Running, of three instances previously created, circled.\n\n\nOnce all the instances are created, you will be able to send the login key files to whoever is responsible for emailing the workshop participants. The login key files are in the directory ../outputs/login-keys/ (within your course/workshop-name directory — instances-management directory in the running example). We usually upload the login-keys directory to a shared GDrive directory and inform someone we have done so.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#stopping-the-instances-shortly-after-within-minutes-they-are-created",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#stopping-the-instances-shortly-after-within-minutes-they-are-created",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Stopping the instances shortly after (within minutes) they are created",
    "text": "Stopping the instances shortly after (within minutes) they are created\n\n\nCode\n\ncsuser@cloud-admin-instance:~\n$ csinstances_stop.sh courses/instances-management/inputs/instancesNames.txt \n\n\n\nOutput\n\ncsinstances_stop.sh is stopping instances specified in input file courses/instances-management/inputs/instancesNames.txt\nStopping instances:\nCreating directory to hold the results of stopping instances:\ncourses/instances-management/outputs/instances-stop-output20230101.182907\nSuccess stopping instance: instance01\nSuccess stopping instance: instance02\nSuccess stopping instance: instance03\n\nOnce you run csinstances_stop.sh, the instances state in the AWS Console will change from Running to Stopping as shown below, and after a short while the state will change to Stopped, and will remain so until you run another script that changes the state of the instances.\n\n\n\n.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#re-starting-the-instances-just-before-the-workshop",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#re-starting-the-instances-just-before-the-workshop",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Re-starting the instances just before the workshop",
    "text": "Re-starting the instances just before the workshop\n\n\nCode\n\ncsuser@cloud-admin-instance:~\n$ csinstances_start.sh courses/instances-management/inputs/instancesNames.txt \n\n\n\nOutput\n\ncsinstances_start.sh is starting instances specified in input file courses/instances-management/inputs/instancesNames.txt\nStarting instances:\nCreating directory to hold the results of starting instances:\ncourses/instances-management/outputs/instances-start-output20230101.185724\nSuccess starting instance: instance01\nSuccess starting instance: instance02\nSuccess starting instance: instance03\n\nOnce you run csinstances_start.sh, the instances state in the AWS Console will change from Stopped to Pending (momentarily), and then to Running and will remain so until you run another script that changes the instances state.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#deleting-the-instances-and-all-their-resources-once-the-workshop-is-over",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#deleting-the-instances-and-all-their-resources-once-the-workshop-is-over",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Deleting the instances and all their resources once the workshop is over",
    "text": "Deleting the instances and all their resources once the workshop is over\n\n\nCode\n\ncsuser@cloud-admin-instance:~\n$ csinstances_delete.sh courses/instances-management/inputs/instancesNames.txt \n\n\n\nOutput\n\ncsinstances_delete.sh is terminating instances specified in input file courses/instances-management/inputs/instancesNames.txt\nTerminating instances:\nCreating directory to hold the results of deleting instances: \nSuccess terminating instance: instance01\n..\nDeleting login key pairs:\nSuccess deleting login-key: login-key-instance01; instance: instance01\n..\nDeleting domain names:\nSuccess deleting domain: instance01.cloud-span.aws.york.ac.uk; ip: 99.80.179.133\n..\nDisassociating following elastic IP addresses:\nSuccess disassociating elasticIP, instance: instance01; eipAssociationId: eipassoc-0ff7c16e5ff5f7178\n..\nDeallocating elastic IP addresses:\nSuccess deallocating eip: 99.80.179.133; instance: instance01; eipAllocationId: eipalloc-0ccacb1c92d26ec7f\n..\n\nYou can delete instances in any state — you don’t need to stop instances to delete them.\nOnce you run csinstances_delete.sh, the instances state in the AWS Console will change from Stopped or Running to Shutting-down, and after some minutes to Terminated, and after some more minutes the terminated instances will no longer be shown in the AWS Console.\nThe output box above shows only the main steps of csinstances_delete.sh in deleting instances and related resources, namely: - Terminating instances - Deleting login key pairs - Deleting domain names - Disassociating elastic IP addresses and - Deallocating elastic IP addresses\nYou should always see a Success … message for each resource that is terminated, deleted or deallocated, but not always for disassociating elasticIPs. Instead, you may see the error in the callout below. There is nothing to worry about this message, ignore it. But you should not ignore an error in any other step — which should not happen if your configuration is valid; the Scripts have not failed since we got them right.\n\n\n\n\n\n\n“Error disassociating elasticIP, instance: instance01; …”.\n\n\n\nThis error may happen because instances are deleted first, and by the time the Script that disassociates IP addresses from instances is run, some of the associations of IP addresses to instances may no longer be valid/existant. This is more likely to happen if an instance is stopped when csinstances_delete.sh is run. If an instance is running, shutting it down and then terminating it will take longer, and hence its association of IP address to instance is more likely to be valid when it is to be disassociated, which will result in successfully disassociating the IP address.\n\n\n\nThe results of stopping, starting and deleting instances are also saved to files\nThe results of running csinstances_stop.sh, csinstances_start.sh and csinstances_delete.sh are also saved within sub-directories in the ../outputs/ directory.\nRun the ls command below to look at the sub-directories that were created after running those scripts.\n\n\nCode\n\ncsuser@cloud-admin-instance:~\n$ ls courses/instances-management/outputs/\n\nThe output of ls should be similar to this one:\n\n\n\n.\n\n\nThe newly created sub-directories are those in boxes; their names are suffixed with the date and time when the relevant script was run. Inside each sub-directory there is a file for each request made by the relevant script, one request for each instance or related resource.\nWe won’t look into these files. Their main use is to register the results of AWS requests in case of errors happening. They were essential while developing the Scripts to get them right.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#create-instances-in-two-steps-to-avoid-unnecessary-costs",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#create-instances-in-two-steps-to-avoid-unnecessary-costs",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Create instances in two steps to avoid unnecessary costs",
    "text": "Create instances in two steps to avoid unnecessary costs\nYou can avoid some of the cost of deploying instances by “creating instances” in two steps. You will first run the script csinstances_create1stPart.sh, and a few days later (just before the relevant workshop starts) the script csinstances_create2ndPart.sh. As shown below, you run those two scripts in the same way as you run all the other scripts, passing in the “instancesNamesFile” that contains the names of the instances to create:\n\n\nCode\n\ncsuser@cloud-admin-instance:~\n$ csinstances_create1stPart.sh  courses/instances-management/inputs/instancesNames.txt \n\n##### and a few days later:\ncsuser@cloud-admin-instance:~\n$ csinstances_create2ndPart.sh  courses/instances-management/inputs/instancesNames.txt \n\nDoing so will save a significant cost if you are running a workshop that requires relatively large instances in terms of compute and storage capacity, up to about US $300 per day (as at 20230414), for 50 instances of type t3.2xlarge, each instance with 240GB storage. The savings come out as follows. Recall that the script csinstances_create.sh first runs the script that creates the login keys, then the script that creates the instances, then .. the IP addresses and finally .. the domain names. Of all these resources, it is the instances that are more costly. The script csinstances_create1stPart.sh only creates the login keys, the IP addresses and the domain names. You will then be able to send the workshop participants their login key and instance domain name, say, on a Friday. On the following Monday you will then run csinstances_create2ndPart.sh to create the instances, associate the instances to the IP addresses, and to configure the instances.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#avoid-modifying-an-instancesnamesfile-that-you-have-already-used-to-create-intances",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#avoid-modifying-an-instancesnamesfile-that-you-have-already-used-to-create-intances",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Avoid modifying an “instancesNamesFile” that you have already used to create intances",
    "text": "Avoid modifying an “instancesNamesFile” that you have already used to create intances\nIn the example above, you should not add the instance name instance04  to the file instancesNames.txt  (that you previously used to create instances01, ..02 and  ..03), and then run again csinstances_create.sh instancesNames.txt — it will fail as shown in the screenshot below:\n\n\n\n.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#the-scripts-check-instance-operations-are-valid-given-the-state-of-the-running-environment",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#the-scripts-check-instance-operations-are-valid-given-the-state-of-the-running-environment",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "The Scripts check  instance operations are valid  given the state of the running environment",
    "text": "The Scripts check  instance operations are valid  given the state of the running environment\nRecall (from Section 3 Create the Instances) that login keys are created first, then instances, etc. Login keys are created by the script aws_loginKeyPair_create.sh which, as you can see in the screenshot above, first checks whether the login key files for the instances to be created exist or not, aborting its execution if any such file exists. In the run shown in the screenshot, aws_loginKeyPair_create.sh found the login key files for instances01, ..02,  and ..03, and hence displayed the message shown and aborted its execution which, in turn, caused csinstances_create.sh to abort its execution as well.\nAs stated in that message, the files that were found contain the AWS resource IDs of login keys already created. Those resource IDs are needed to delete the login keys from your AWS account. The Scripts do not overwrite files that contain such resources IDs. If those files are overwritten, or lost, before you delete the corresponding instances and related resources (running csinstances_delete.sh), you will need to use the AWS Console to delete manually the corresponding instances, login keys, IP addresses and domain names.\nIf you want to create instances with names you have already used, you must first delete the instances already created and their related resources (running csinstances_delete.sh), then delete or rename the ../outputs/ parent directory, and finally create the instances. We have done so only for some testing, see the Troubleshooting section.\nAll the Scripts that create AWS resources carry out a similar check to that carried out by aws_loginKeyPair_create.sh. For each instance name in the “instancesNamesFile” passed in to csinstances_create.sh, each script checks whether the instance, or the resource for that instance, has been created or not, which amounts to checking whether the file with the corresponding AWS resource ID exists or not. If any such file does exist, the script aborts its execution without issuing any AWS request to create resources.\nAll the Scripts that delete AWS resources carry out a similar check but act on the opposite. … If any such file does not exist, the script aborts its execution without issuing any AWS request to delete resources. The script aws_instances_configure.sh does this check.\nGiven a set of instances names as specified in an “instancesNamesFile”, the two checks above guarantee that all or none of the instances, and/or related resources, are created or deleted.\nFinally, all the Scripts aws_*.sh check that the “instancesNamesFile” passed in to them has only one value (one instance name) in each line. Thus, if you inadvertently passed in to the Scripts the file name resourcesIDs.txt or tags.txt, which both have two values in each line, the Scripts will abort their execution.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/02-instances-management.html#using-multiple-instancenamesfiles-to-manage-unforseen-instances-management-requests",
    "href": "docs/lesson02-managing-aws-instances/02-instances-management.html#using-multiple-instancenamesfiles-to-manage-unforseen-instances-management-requests",
    "title": "Instances Management Tasks Using the Scripts",
    "section": "Using multiple “instanceNamesFile”s to manage unforseen instances management requests",
    "text": "Using multiple “instanceNamesFile”s to manage unforseen instances management requests\nThere is no problem with having multiple “instancesNamesFile”s in an ../inputs/ directory.\nThe main issue is how to name those multiple files so that you keep track of what happens, regarding instance management, throughout a workshop.\nThe listing below illustrates the naming convention we follow to name multiple “instancesNamesFile”s to handle similar requests to the ones described in the introduction to this section.\nThe listing shows the files in the inputs directory of a workshop we ran through late October and November 2022:\n\n\nOutput\n\ninstancesNames20221028-create-301-25.txt\ninstancesNames20221031-create-326.txt\ninstancesNames20221031-create-327.txt\ninstancesNames20221031-create-328.txt\ninstancesNames20221101-create-329.txt\ninstancesNames20221109-delete-307.txt\ninstancesNames20221114-delete-303,315,321.txt\ninstancesNames20221115-create-again-321.txt\ninstancesNames20221121-delete-310,314,320,321,323,325.txt\ninstancesNames20221123-stop-306.txt\ninstancesNames20221128-delete-302,304-05,308-09,311-13,316-19,322,324,326-29.txt\ninstancesNames20221130-delete-301.txt\nresourcesIDs.txt\ntags.txt\n\nThe workshop used instances of type t3.2xlarge, each instance with 8 processors and 32 GigaBytes of main memory and 240 GB of secondary storage — not cheap. The instances were to run for 4 weeks unless the participants would not make progress which we checked weekly looking at the command history and whether relevant results files existed. We would delete instances that showed no progress was made.\nFrom the file listing above we can recall the following:\n\nOn 28 October we created the 1st file at the top and run csinstances_create.sh courses/../inputs/instancesNames20221028-create-301-25.txt in order to create 25 instances named: instance301, instance302, instance303, …, instance325.\nOn 31 October we received 3 requests, at different times, to create one more instance. Upon receiving each request, we created another “instanceNameFile” (2nd, 3rd and 4th files in listing above) with only one instance name inside (instance326, instance327, instance328 respectively), and run csinstances_create.sh with each file.\nOn 1 Novemeber we received another request to create one more instance and handled it as just described to create instance329.\nOn 9 November we deleted instance307 (for not showing progress):\n\nwe made a copy of instancesNames20221028-create-301-25.txt onto instancesNames20221109-delete-307.txt.\nopened the latter with our text editor and deleted all lines except the line with the instance name instance307.\nwe then run csinstances_delete.sh courses/../inputs/instancesNames20221109-delete-307.txt.\n\n\nThe other “instancesNamesFile”s in the list were handled similarly to the way the event on 9 November was handled, namely: - creating a new file containing only the names of the target instances. - naming the file instancesNamesDate-operation-instancesNumbersList.txt — where operation is create, stop, start, or delete. - running the relevant csinstances_*.sh script to create, stop, start or delete the target instances.\nThe tedious part of this file naming convention is specifying the intancesNumbersList. However, it is not required often and it gives you an accurate overview of the instances operations you have performed.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "Instances Management Tasks Using the Scripts"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html",
    "title": "AMIs Management",
    "section": "",
    "text": "Prerequisites\n\n\n\nPlease read Workshops Organisation if you haven’t done so. To complete this episode you will need:\n\nto have completed the previous episode: Instances Management Tasks Using the Scripts.\nif you are self-studying the course or attending a workshop using your AWS account:\n\nto have created your AWS account as described in Create Your AWS Account (Episode 1, Lesson 1).\nto have configured your AWS account as described in Configure Your AWS Account (Episodes 2, Lesson 1).\nto have configured your terminal environment as described in either of these episodes:\n\nConfigure Your Terminal Environment (Episode 3, Lesson 1) — or\nConfigure Your AWS CloudShell Environment (Episode 4, Lesson 1)\n\nto have configured instances internet access as described in Configure Instances Internet Access (previous episode, this lesson).\nyour base domain name.\nthe AWS resource IDs of your: host zone, security group, and subnet.\nthe AWS Console login details of your IAM user account: login page, username and password.\n\nif you are attending a workshop using a Cloud-SPAN AWS account (and an AWS Linux instance), you will be given the necessary information at the workshop.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#sections",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#sections",
    "title": "AMIs Management",
    "section": "Sections",
    "text": "Sections\n\nCreate an ‘instance-to-become-AMI’\nIn this section you are going to create an ‘instance-to-become-AMI’ using the file-directory structure we use to manage such instances.\nCreate an AMI and make it Public in the AWS Console\nDelete an AMI in the AWS Console\nWe use the AWS Console to create an AMI, to make it public or private, and to delete it. Sections 2 and 3 will guide you to perform those tasks with the AWS Console. — In case you are wondering about scripting AMIs management, yes AMIs can also be managed (created, deleted, etc.) with the AWS CLI, and hence a set of scripts (like the Scripts that manage instances) could be developed to manage AMIs. We haven’t had the need to do so, however: the AMI tasks we need to perform are rather simple in the AWS Console and only rarely needed in the Cloud-SPAN project, so far.\nInstances management for courses, AMIs and tests\nSection 4 introduces the file-directory structure we use to manage instances to-become-AMIs. This section describes other AMI management practices we follow.\nWhen to configure an ‘instance-to-become-AMI’\nBased on our experience in configuring instances to-become-AMIs within the Cloud-SPAN project, this section presents our viewpoint as to when and how to create an AMI.\nConfigure an ‘instance-to-become-AMI’\nThis section shows our approach to update both system software and end-user software using various scripts we have developed to automate some of the tasks involved.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#login-to-the-aws-console-with-your-iam-account-user",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#login-to-the-aws-console-with-your-iam-account-user",
    "title": "AMIs Management",
    "section": "Login to the AWS Console with your IAM account user",
    "text": "Login to the AWS Console with your IAM account user\nOnce you are logged in to the AWS Console, go to the page “EC2 - Instances” as follows:\n\ntype EC2 in the AWS search box at the top.\nin the page that appears, “EC2 Dashboard” (not shown), click on Instances on the left menu pane.\n\nYou should now be presented with the “Instances” page, similar to the page below.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#stop-the-instance-if-it-is-running",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#stop-the-instance-if-it-is-running",
    "title": "AMIs Management",
    "section": "Stop the instance if it is running",
    "text": "Stop the instance if it is running\nCreating an AMI involves making a copy of the source instance software environment (operating system, end-user software applications and data). In order to ensure the consistency of the copy, we need to stop the instance before the copy starts.\nOn your “Instances” page:\n\nselect your ‘instance-to-become-AMI’ if it is running: check the box to the left of the instance name.\nwe have selected “cloud-admin-instance” in the page below.\nclick on the drop-down menu Instance state at the top.\nclick on Stop instance.\nwait for the instance state to change to Stopped.\n\n\n\n\n.\n\n\n\n\n\n\n\n\nYou may need to reboot the instance first, and then stop it.\n\n\n\nYou may have already seen a message like the one below after updating the operating system in your personal computer:\n“Your computer needs to restart for changes to take effect.”\nIf you have updated the operating system in the ‘instance-to-become-AMI’ as part of the configuration you intend for the new AMI, then you need to reboot the instance first and then stop it before creating an AMI from it. If you don’t, if you create the AMI without rebooting the instance, then each of the instances that you create with that AMI will have to be rebooted after being launched. Hence you just delay doing it and will have it multiplied.\nWe always reboot an ‘instance-to-become-AMI’ even if we only update end-user software applications or data so that any state or data is flushed from main memory onto secondary storage (which is the software environment to copy). The page above shows the option to Reboot an instance.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#select-the-instance-and-the-options-to-create-an-image-ami-from-it",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#select-the-instance-and-the-options-to-create-an-image-ami-from-it",
    "title": "AMIs Management",
    "section": "Select the instance and the options to create an image (AMI) from it",
    "text": "Select the instance and the options to create an image (AMI) from it\nOnce your instance is stopped, do as follows (see page below):\n\nselect your instance if it is not selected: check the box to the left of the instance name.\nclick on the drop-down menu Actions at the top\nclick on Image and templates\nclick on Create image.\n\n\n\n\n.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#enter-a-name-and-other-info-for-the-ami-and-click-on-create-image",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#enter-a-name-and-other-info-for-the-ami-and-click-on-create-image",
    "title": "AMIs Management",
    "section": "Enter a name and other info for the AMI and click on Create image",
    "text": "Enter a name and other info for the AMI and click on Create image\nYou will now be presented with the page below: “Create image”. Type a name and a description for your AMI in the first two highlighed fields from the top. The description field is optional; but it’s useful to write a brief description of the AMI configuration so you can easily recall what the AMI is about.\nThe highlighted option below, No reboot and its checkbox Enable, should be as shown: unchecked. Uncheck it if it is checked. By default, AWS shuts down and reboots the ‘instance-to-become-AMI’ if it is running in order to get a consistent state of the instance storage. If you check it, you Enable (both no shut down and) No reboot. And AWS cannot guarantee a consistent state for the AMI. This option is not applicable if you (reboot and) stop the instance as suggested.\nThe highlighted option below and to the right, Delete on termination and its checkbox Enable, should be as shown: checked. Check it if it is unchecked. This option means that, for all instances created from the AMI you are about to create, once the instances are terminated/deleted, their storage/volumes should be deleted. We want this behaviour — we don’t want to delete each such volume individually: the Scripts don’t handle deleting those volumes. On the other hand, you may find usefull to delete an instance but not its storage: you will no longer be able to stop, start and login to the instance, but you will be able to attach its storage to another (runnable) instance. We did something along these lines to reduce the size of the disk and file system of an AMI.\nThe value of the field Size, at the bottom of the page in the middle, is 30 GB, and is the size of the storage of the ‘instance-to-become-AMI’. The same size will be used for the storage of the AMI to be created unless you increase it. You cannot decrease it: it is assumed that the operating system inside is controlling all the storage (even if it is not) — decreasing it would corrupt the file system.\n\n\n\n.\n\n\nScroll down the “Create image” page until you see the end of the page as shown below. The first highlighted option from the top, Tag image and snaphots together, should be checked. Check it if it is unchecked. Now click on Add new tag on the bottom left (we have already done so in the page below) so that two boxes will appear, titled Key and Value - optional. In the Key box, enter Name (literally), and in the Value box enter the name you entered for your AMI before, see the page below. The benefit of doing this is explained below. You can add more tags if needed.\nFinally, click on Create image at the bottom right. You will be presented with the “Instances” page again, showing at the top a message like this one (our emphasis):\n“Currently creating AMI ami-0f6c9742b2f6824bb from instance i-00c65a40a9d194cfc. Check that the AMI status is ‘Available’ before deleting the instance or carrying out other actions related to this AMI”.\n\n\n\n.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#check-your-ami-and-make-it-public-or-private",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#check-your-ami-and-make-it-public-or-private",
    "title": "AMIs Management",
    "section": "Check your AMI and make it public or private",
    "text": "Check your AMI and make it public or private\nTo check your AMI, go to the (EC2) “Amazon Machine Images (AMIs)” page: on the left menu pane, scroll down (or up) to find AMIs and click on it.\nYou will be presented with a page like the one below. The page below shows (in tabular form) the attributes/properties of two AMIs that we created for this section. The attribute Name (first column from left), corresponds to the value of the tag key that we suggested to add. The third attribute, AMI name, is the name of the first field in the page above where you entered the name for your AMI when your created it.\nYou can see in the page below that we didn’t add such a tag for the first AMI listed, so it has no value for Name, but we did add the tag for the second AMI using the same value for Name that we used for AMI name. The benefit of this tagging will be apparent when we delete the AMI below.\n\n\n\n.\n\n\nIn the AMIs page shown above, there are quite a few more attributes for each AMI in that table on the right (scroll the table left to see other AMI attributes, there is a bar below the table to do so, not shown in the page). Other AMI attributes include:\n\nVisibility\nPlatform (Linux, Windows, etc.)\nCreation date\netc.\n\nVisibility is about whether an AMI is private or public. If you create an AMI you can keep it private for your own exclusive use or make it public so that other people (outside your AWS account) can find it and use it to create instances from it. Public visibility extends to the region where the AMI was created only.\nTo make an AMI public or private, do as follows in the AMIs page:\n\n\n\n.\n\n\n\nselect the AMI: check the box to the left of the AMI Name\nclick on the drop-down menu Actions at the top right\nclick on Edit AMI permissions — in the page that appears, “Edit AMI permissions” (not shown):\n\nselect Public or Private under the heading “AMI Availability”, then scroll down and\nclick on Save changes",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#delete-the-ami-first",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#delete-the-ami-first",
    "title": "AMIs Management",
    "section": "Delete the AMI first",
    "text": "Delete the AMI first\nTo delete an AMI, do as follows on the (EC2) AMIs page (see page below):\n\nselect the AMI: check the box to the left of the AMI Name\nclick on the drop-down menu Actions at the top right\nclick on Deregister AMI\n\n\n\n\n.\n\n\nOnce you click on Deregister, a window like the one below will pop up.\n\n\n\n.\n\n\nIn the page above, we have clicked on Deleted associated snapshots (in the middle). Doing so displayed the message:\n“Snapshots are not automatically deleted when you deregister and AMI. After you deregister the AMI, you can delete the snapshots in the Snapshots Screen[link].”\nAs the message states: you can delete the storage/snapshots of an AMI only after you delete/deregister the AMI. You have two options to do so. We will describe first the option we have been using.\nIn the option we use, in the popped up window in the page above:\n\nclick on Deregister AMI (in orange) to confirm deletion of the AMI:\nthe AMIs page will be displayed again with the message “Successfully deregistered ami-042b2f6824bbf6c97.” in green at the top.\n\nOnce you click on Deregister AMI, the AMI as such will be deleted (you won’t be able to create instances from it). You now need to delete the snapshots.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#delete-the-storagesnapshots-of-the-ami-option-we-use",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#delete-the-storagesnapshots-of-the-ami-option-we-use",
    "title": "AMIs Management",
    "section": "Delete the storage/snapshots of the AMI (option we use)",
    "text": "Delete the storage/snapshots of the AMI (option we use)\nTo delete the snapshots of an AMI, go to the (EC2) “Snapshots” page: on the left menu pane, scroll down (or up) to find Snapshots and click on it. You will then be presented with a page like the one below.\nDo as follows on this page:\n\nselect the snapshot/s to delete: check the box to the left of the snapshot Name.\nclick on the drop-down menu Actions at the top right\nclick on Delete snapshot\n\n\n\n\n.\n\n\nThat’s it. You have deleted the AMI in its entirety.\nIn this option to delete the snapshots of an AMI, note that we rely on the tagging we suggested to add in the instructions to create an AMI. That is:\n\nselecting the option Tag image and snapshots together and\nadding a Tag with the Key Name and Value your-AMI-name\n\nIn the page above, the snapshot with no Name (the second one of those checked) is the snapshot attached to the AMI for which we did not specify that tag. With no such tags, you will need to somehow ensure that you are deleting the right snapshot, by looking at the details of the target AMI to get the IDs of the attached snapshots.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#delete-the-storagesnapshots-of-the-ami-other-option",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#delete-the-storagesnapshots-of-the-ami-other-option",
    "title": "AMIs Management",
    "section": "Delete the storage/snapshots of the AMI (other option)",
    "text": "Delete the storage/snapshots of the AMI (other option)\nAlternatively, you can delete the snaphots of an AMI as follows. In the page with the window that pops up after you clicked on Deregister AMI for the first time (shown below again), do as follows:\n\nclick on Snapshots screen (in blue) before clicking on Deregister AMI.\nThis will open the “Snapshots” page in a new browser tab, listing only the snapshots attached to the AMI/s you previously selected to deregister — hence you don’t need the Names of the relevant AMI to identify the snapshots.\nclick on Deregister AMI — you need to deregister the AMI before deleting the snapshots.\nin the “Snapshots” page in the new browser tab\n\nselect the snapshots to delete\nclick on Actions at the top of the page\nclick on Delete snaphot\n\n\n\n\n\n.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#our-working-directory-to-run-the-scripts",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#our-working-directory-to-run-the-scripts",
    "title": "AMIs Management",
    "section": "Our working directory to run the Scripts",
    "text": "Our working directory to run the Scripts\nThe tests directory is located at the same level as the directories courses and amis. Our actual working directory where we run the Scripts (in our Linux machine) looks like this:\n\n\nCode\n\njorge@wine:~/software/york/cloud-SPAN/aws-instances\n$ ls\n\n\n\nOutput\n\namis  courses  tests  the-Scripts\n\nAnd we run the Scripts specifying:\n\neither amis or courses or tests.\none or more intermediate directories (before the inputs directory where the configuration files instancesNames.txt, resourcesIDs.txt and tags.txt reside).\nthe inputs directory.\nthe target instancesNames.txt file.\n\nExamples:\n\n\nCode\n\njorge@wine:~/software/york/cloud-SPAN/aws-instances\n$ csinstances_create.sh amis/ami09-metagenomics-instance/metagenomicsT3instance/inputs/instancesNames01.txt \n$ csinstances_create.sh courses/genomics20221206-7/inputs/instancesNames.txt\n$ csinstances_create.sh tests/t003-cloud-admin-course-instance-UoYacc20221107/inputs/instancesNames-cloud-admin-instance.txt\n\nThe file-directory structure is rather flexible. We are only bound to specify first (the type of the target instances through the name of the directory) amis or courses or tests, and down the path the inputs directory just before the target instancesNames.txt whose name we can choose according to need.\nThe path in the first example has two intermediate directories while the two other examples have only one (as in all the code examples we showed before). In the first example, we started the configuration of the meteganomics ‘instance-to-become-AMI’ using the AWS instance type t2.medium which we inherited from the Data Carpentries AMI. Instance type t2 cannot scale as much as we needed to, while instance type t3 can. So we changed to type t3 which involve creating a new temporary AMI and we decided to handle it on a new intermediate directory called metagenomicsT3instance under ami09-metagenomics-instance. We could also have handled it as ami09-metagenomics-T3instance under amis.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#instances-names-we-use",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#instances-names-we-use",
    "title": "AMIs Management",
    "section": "Instances names we use",
    "text": "Instances names we use\nThe actual names we use when creating instances are suffixed with the name of the AMI template from which the instances are created. You don’t need to follow this naming convention but it is helpful under some circumstances.\nIt was helpful for us in the beginning, when we had to add some functionality/configuration into a new AMI relatively frequently until our AMIs got “stable” — meanwhile we had instances running that were created from different AMI templates. Anyway, we needed displayed in the AWS Console the name of the source AMI of each instance. So instances names in our instancesNames.txt files have this form:\n\n\nOutput\n\ninstance306-srcCS-AMI09-MetaGen\ncloud-admin-instance-srcCS-AMI08\nmetagenomics-instance001-srcCS-AMI09-MetaGen\nmetagenomics-Joao-srcCS-AMI09-MetaGen\n\nThe instance name proper, the one that is used for the instance domain name and hostname of each instance, is the substring from the beginning of each line up to before the substring -src (for source AMI name). After src you can add the name of your AMI. The Scripts extract the instance proper name to configure the instance domain name and host name within each instance. But use the whole name as the value for the instance tag Name which is displayed in the AWS Console, as shown below:\n\n\n\n.\n\n\nWe can handle the name of the source AMI as part of the instance name but then it will appear in both the instance domain name and the host domain name and this would be distracting to end users.\nAs mentioned above, you don’t need to suffix your instances names but obviously you should not use the substring -src anywhere in an instance name unless you intend to add the source AMI name as we do. You can also edit the Scripts to get rid of that suffix handling.\nThe list of instances names in the output box above is not meant to be the contents of an actual “instancesNames.txt” file that can be used to create/manage instances with the Scripts. The Scripts cannot create instances using two or more AMI templates — but only one.\n\n\n\n\n\n\nExercise: How would you handle a Code Retreat that requires instances from two or more AMI templates?\n\n\n\nWe currently manage three AMIs. One AMI for the Cloud-SPAN Prenomics and Genomics courses. Two AMIs for two versions of the Metagenomics course that differ in the ’omics data that is analysed. When we run each course we only need to create instances from one AMI template. But we also run Code Retreats in person with students of the three courses and we launch instances of type Genomics and Metagenomics.\nHow would you manage the instances for such a code retreat within the courses directory?",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#requirements-for-which-we-have-created-a-new-ami",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#requirements-for-which-we-have-created-a-new-ami",
    "title": "AMIs Management",
    "section": "Requirements for which we have created a new AMI",
    "text": "Requirements for which we have created a new AMI\n\nupdating software or data\nreducing the storage size\nincreasing the storage size\nchanging AWS configuration",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#updating-software-or-data",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#updating-software-or-data",
    "title": "AMIs Management",
    "section": "Updating software or data",
    "text": "Updating software or data\nUpdating software or data or both is the obvious reason to create a new AMI — it literally means any change in software or data, including:\n\nupdating or upgrading the operating system\nupdating any other software:\n\nend-user software applications to be used in a course\nadmin software (scripts) that you (as instances manager) need installed in each instance, for example, the Scripts that activate the csuser account in each instance, as outlined in the previous episode.\n\nupdating data for a course\n\nIt is not convenient and we find it unmanageable to create a new AMI every time any item in that list changes. The items that do require creating a new AMI straight away are updating data for a course and sometimes updating admin scripts that you need installed in each instance (to be created from the AMI). In our experience all other items can wait, should be assessed, and when possible combined into a new AMI.\n\nUpdating data\nUpdating data requires a new AMI because the data to be updated/added is the subject of (will be processed and analysed in) a course, or you may need to delete some data because it is too big, no longer needed, or you need space in the AMI for something else.\nBut wait, would it not be better to update the data on each instance (created from a currently used AMI) using some new scripts? And thus avoid creating a new AMI.\nIf the data is relatively big, it is much better to update the data only once, in the new AMI, rather than mutilple times in each of the instances because the entire process of creating and preparing the instances will take much longer. Also, the new scripts to update the data may be complex and ad hoc for each data update, at least in the beginning — until you identify some pattern that enables you to configure the scripts and data transfers in a generic way.\nIf the data is relatively small, the scripts point regarding complexity may still apply. It will be more complex to design the new scripts to update data in each instance than just updating the data in the new AMI only once.\nIf you decide to design new scripts to update data in multiple instances (as opposed to creating a new AMI), you should not invoke the new scripts within the Scripts. Run the Scripts first to create the instances, and then run the new scripts that update data.\n\n\nUpdating admin scripts\nUpdating admin scripts that you need installed in each instance may, or may not, require creating a new AMI straight away.\n\nScenario that required creating a new AMI straight away\nThe first AMI we created was a copy of the Genomics Data Carpentry AMI. Instances created from the Data Carpentry AMI are also accessed with ssh but using an IP address and a password for the dcuser, which password is the same for all instances. For the Cloud-SPAN instances, we decided to use domain names (instead of IP addresses) and no password for the Cloud-SPAN csuser but an encrypted login key file for each instance. This required, among other things, to create and upload into the Cloud-SPAN AMI a few scripts into the ubuntu user account, in the /home/ubuntu/bin directory. These scripts make the ubuntu user share, with the csuser, the public key part of the login key created to access an instance (injected by AWS in /home/ubuntu/.ssh/authorized_keys), so that both users can use the same login key file created for each instance. Each instance created from the first Cloud-SPAN AMI has those scripts which are invoked by the script aws_instances_configure.sh as part of the configuring of each instance.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#you-can-only-use-the-scripts-with-cloud-span-amis",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#you-can-only-use-the-scripts-with-cloud-span-amis",
    "title": "AMIs Management",
    "section": "You can only use the Scripts with Cloud-SPAN AMIs:",
    "text": "You can only use the Scripts with Cloud-SPAN AMIs:\nBecause of that “login key” and “domain name” configuration to access Cloud-SPAN instances, the Scripts can only be used with a Cloud-SPAN AMI as the template from which to create instances.\nIf you want to use the Scripts and that configuration is OK with you, you can still create your own AMI by configuring end-user software applications and data.\nIf you want to use the Scripts but change that configuration (for example, you want to use IP addresses or not using a login key for the csuser, etc.), you will need to change both the AMI configuration and change the script aws_instances_configure.sh accordingly. {.callout}\n\nScenario that did not require creating a new AMI straight away\nThe instances for the Cloud-SPAN Metagenomics courses have each 240GB of secondary storage. The input data that is analysed during the course is about 17GB, but the output data produced from various analyses grows over 100GB. Before the analyses, the input data, the operating system and the metagenomics software applications require less than 50 GB.\nHence, we could have created an AMI of about 50GB and, on creating each instance for the course, increase the storage size of each instance to 240GB after the configuration step of each instance by aws_instances_configure.sh. Instead we created the Metagenomics AMIs of size 240GB.\nThe main reason for that decision was that we ran out of time to design and test the scripts to increase storage. It was safer to have the AMI with 240GB ready and hence the instances also ready once created.\n\n\nUpdating the operating system and end-user software\nWe have only upgraded the Linux operating system only once. The Data Carpentries AMI from which we created the first Cloud-SPAN AMI was configured with Linux Ubuntu 16.04. The Cloud-SPAN Genomics and Metagenomics AMIs are version 20.04. We don’t see the need to upgrade them to the stable version 22.04 yet.\nLikewise we have only updated the end-user software applications in each AMI only once, when we upgraded the Linux operating system from the Data Carpentry version.\nThere is no need to update the system or end-user software unless changes to the corresponding courses justify updating the software, something like: somebody has used a more recent version of a software application and has changed the course materials with more accurate results or another way of using the application, etc.\nWhenever possible, install end-user software locally in the csuser account, either in /home/csuser/bin or other local directory. You will have more control as to what to delete in order to configure and create a new AMI.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#reducing-storage-size",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#reducing-storage-size",
    "title": "AMIs Management",
    "section": "Reducing storage size",
    "text": "Reducing storage size\nReducing storage size is complex, and we cannot see a way to automate it yet. We have done it a few times and hopefully won’t do it again in the context of the Cloud-SPAN project — you may not either.\nWe decided to reduce the size of the Cloud-SPAN AMI for the Prenomics and Genomics courses for two reasons. Those courses don’t require instances bigger than 30GB, and 30GB is the instance size limit in the AWS Free Tier. Thus, Cloud-SPAN students can create their own Genomics instance without paying for one year as described in the Cloud-SPAN course Create Your Own AWS Instance.\nAs mentioned earlier, the first AMI we created was a copy of the Data Carpentries AMI, which was 120GB. We reduced it to 30GB following the instructions in How To Shrink Amazon EBS Volumes (Root Or Non-Root) — this site has unfortunately been unavailable some times since we used it — google its title for some options.\nWe followed those instructions for storage volumes called /dev/xvda and /dev/xvda1 which are used in instances of type t2. Cloud-SPAN AMIs are now type t3 whose storage volumes are called /dev/nvme0n1 1 and /dev/nvme0n1p1.\nHopefully you won’t need to reduce storage below 30GB.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#increasing-storage-size",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#increasing-storage-size",
    "title": "AMIs Management",
    "section": "Increasing storage size",
    "text": "Increasing storage size\nIncreasing storage size is rather simple and efficient in AWS.\nWe had to increase storage size for the Cloud-SPAN Metagenomics course instances, up to 240GB, for the reasons already mentioned above. Starting with the Cloud-SPAN AMI for the Genomics course (30GB), we created an instance into which we uploaded a script (into the ubuntu account ~/bin directory) that increases storage size, and then created a new AMI. All the instances created from this AMI can run that script to increase the storage size dynamically, that is, without having to log out from the instance. The script is called aws_storageEBS_increase.sh. Its output when run with no parameters is shown below:\n\n\nCode\n\nubuntu@cloud-admin-instance.cloud-span.aws.york.ac.uk:~ $ aws_storageEBS_increase.sh \n\n\n\nOutput\n\naws_storageEBS_increase.sh increases the size of the instance disk (EBS storage and the file system)\nup to the given number of GigaBytes (GB) if such number is larger than the current size of the disk.\n \nusage: \n  aws_storageEBS_increase.sh newSizeOfDiskInGBs\n\nExample:       aws_storageEBS_increase.sh 120 \n \n  - increases the size of the disk and file system to be of 120 GB. \n  - the current disk size must be smaller than 120 GB\n  - note that the file system size may be shown as slightly smaller than disk space:\n    try command: \"df -h .\"\n\nBack to the development of the Cloud-SPAN Metagenomics AMI, after we created the AMI with the script aws_storageEBS_increase.sh inside, we created an instance, logged into the instance, ran that script to increase the size up to 240GB, configured the metagenomics software and data, and then created the Metagenomics AMI.\n\n\n\n\n\n\nExercise: How would you increase the size of Metagenomics instances dynamically?\n\n\n\nThat means, how would you?\n\ncreate Metagenomics instances using an AMI 50GB big, and then\nincrease the size of each instance to 240GB running the script aws_storageEBS_increase.sh in each instance after the instance is created.\n\n\n\n\nYou will hopefully only need to increase storage size (and not decrease it)\nThe size of the Cloud-SPAN Genomics AMI and instances is 30GB. Small enough to be in the AWS Free Tier. Hopefully you will only need to increase its size as outlined above and not to decrease it.\nThat is, should you need to create a new AMI, you should start with the Cloud-SPAN Genomics AMI, the one you used to create instances with the Scripts in the previous episode, as you will have the option to increase its size easily. However, all depends on your needs, see the last section “Put it all together: …”.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#changing-aws-configuration",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#changing-aws-configuration",
    "title": "AMIs Management",
    "section": "Changing AWS configuration",
    "text": "Changing AWS configuration\nThe Cloud-SPAN Metagenomics AMI not only required more storage than the Genomics AMI but also more main memory and more processors which, you will remember, are aspects of the (virtualised) “hardware platform” (not of the software enviroment wich comprises the storage).\nWe were using “hardware platforms” of type t2 (following the Data Carpentries use): t2.small, t2.medium t2.large, etc. For the Metagenomics AMI, at some point we needed to use a larger instance type, r5.4xlarge, but we couldn’t. We got a message saying that type t2 was incompatible with the type of internet access required by type r5.4xlarge, something called Elastic Network Adapter (ENA).\nType t3 instances are ENA compatible, have similar sizes to type t2 (small, medium, etc.), and can use type r5.4xlarge and others. So we change to type t3, meaning that the Cloud-SPAN Genomics and Metagenomics AMIs are type t3 and hence, instances created from them are type t3 as well.\nYou can create t2 instances from a t3 AMI, as follows: in the resourcesIDs.txt file you would use t2.small (or other t2 type) as the instance type but use a type t3 AMI template such as the Cloud-SPAN AMI you used in the previous episode. The opposite doesn’t hold: you cannot create t3 instances from a t2 AMI — you will be able to create instances but you won’t be able to login.\nAgain: should you need to create a new AMI, you should start with the Cloud-SPAN Genomics AMI, the one you used to create instances with the Scripts in the previous episode. It will enable you to increase the storage size of offspring instances dynamically, and being t3 type you can run offspring instances on more instance types.\nBy the way, you can change the instance type of an instance in the AWS Console as follows. Go to the EC2 - Instances page and select the instance, check the checkbox to the left of the instance name, then:\n\nstop the instance: click on Instance state at the top and then on Stop instance\nwait for the instance state to change to Stopped\nchange the instance type: click on Actions at the top, then on Instance settings, and then on Change instance type. A new page will appear where you will be able to change the instance type — save the changes\nrestart the instance.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#updating-system-software",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#updating-system-software",
    "title": "AMIs Management",
    "section": "6.1 Updating system software",
    "text": "6.1 Updating system software\nThe Linux version installed in the ‘instance-to-become-AMI’ that you are about to configure is Ubuntu 20.04.4 LTS. LTS stands for Long Term Support version. “Updating system software” for an LTS version can mean either updating the LTS version with bugs and security patches (that address errors or security vulnerabilities), or updating the LTS version to the next LTS version if available, or both. We will use the term “updating system software” for the first meaning, and the term “updating to the next LTS” for the second meaning.\nWe are going to do the following:\n\nupdating to the next LTS typing each of the commands typically used to update any Ubuntu version to the next LTS, see the bar “Ubuntu LTS versions” below\nupdating system software running our script softwareInstall_genomics_ubuntusr.sh, which performs typical “updating system software” in addition to installing the system libraries required by the Genomics end-user software applications already installed in the ‘instance-to-become-AMI’. Updating system software (with softwareInstall_genomics_ubuntusr.sh) can be performed without updating to the next LTS — we have tried this out only with the Genomics AMI.\ndiscussing the way to installing and removing end-user software applications - first part, which must be performed with the ubuntu user — a second part, which must be performed with the csuser or the new user you create (in step 6.2), is discussed in step 6.3 “Updating end-user software applications”.\n\n\n\n\n\n\n\nUbuntu LTS versions\n\n\n\nLTS versions provide users with software stability for a relatively long period. LTS versions are released every two years on April and receive support through security and bugs patches for up to five years or more — you may be interested in the following:\n\nUbuntu version history\nLong-term support\nThe Ubuntu lifecycle and release cadence\n\nUpdating LTS versions is explained in How To Upgrade to Ubuntu 22.04 Jammy Jellyfish\n\n\n\nUpdating to the next LTS\nYou are logged in as the ubuntu user on your ‘instance-to-become-AMI’. You will enter the following commands one by one: - sudo apt-get update - apt-get upgrade -y - sudo apt-get dist-upgrade - sudo apt autoremove - sudo do-release-upgrade\nSome of these commands print a lot of output as they run. We will only show the most relevant output within a drop-down bar labelled: “Output — command”. We have added comments to some output and commands, like this one: ### comment on output/command. You still can copy-paste the commands as the comments will be ignored by the shell.\nThe first command, sudo apt-get update, updates the list of installed packages with new updates for each package if any. Enter the command and wait until the prompt appears again to enter the next command.\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~ \n$ sudo apt-get update                 ### updates packages list of installed packages\n\n\n\n\n\n\n\nOutput - sudo apt-get-update\n\n\n\n\n\n\n\nOutput\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo apt-get update                 ### updates packages list of installed packages\nHit:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu focal InRelease\nHit:2 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu focal-updates InRelease\nHit:3 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu focal-backports InRelease\nGet:4 https://esm.ubuntu.com/infra/ubuntu focal-infra-security InRelease [7,450 B]\nGet:5 https://esm.ubuntu.com/infra/ubuntu focal-infra-updates InRelease [7,449 B]\nGet:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n...\nFetched 129 kB in 3s (44.4 kB/s)\nReading package lists... Done\nubuntu@instanceToBecomeAMI-Jorge.cloud-span.aws.york.ac.uk:~\n$\n\n\n\n\nThe second command, sudo apt-get upgrade -y, applies the updates: upgrades the packages. The option -y stands for yes to any question regarding applying the udpates, so you don’t have to enter y and Enter to each question; the upgrade just runs to the end. This command may take over 5 minutes to complete.\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~ \n$ sudo apt-get upgrade -y             ### applies updates: upgrades the installed packages\n\n\n\n\n\n\n\nOutput - sudo apt-get-update -y\n\n\n\n\n\n\n\nOutput\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo apt-get upgrade -y            ### applies updates: upgrades the installed packages\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nCalculating upgrade... Done\n..\nThe following packages have been kept back:\n  fwupd libfwupd2 libfwupdplugin5 linux-generic linux-headers-generic linux-headers-virtual linux-image-generic\n  linux-image-virtual linux-virtual python3-software-properties software-properties-common software-properties-gtk\n  ubuntu-advantage-tools\nThe following packages will be upgraded:\n  accountsservice amd64-microcode apache2-bin apparmor apport apport-gtk apt apt-transport-https apt-utils\n...                                                     ### loads of output\nProcessing triggers for libgdk-pixbuf2.0-0:amd64 (2.40.0+dfsg-3ubuntu0.4) ...\nProcessing triggers for dbus (1.12.16-2ubuntu2.3) ...\nProcessing triggers for initramfs-tools (0.136ubuntu6.7) ...\nupdate-initramfs: Generating /boot/initrd.img-5.4.0-109-generic\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\nubuntu@instanceToBecomeAMI-Jorge.cloud-span.aws.york.ac.uk:~\n$\n\n\n\n\nThe third command, sudo apt-get dist-upgrade, performs “any additional upgrades that involve changing dependencies, adding or removing new packages as necessary. This will handle a set of upgrades which may have been held back by the previous apt upgrade step”.\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~ \n$ sudo apt-get dist-upgrade\n\n\n\n\n\n\n\nOutput - sudo apt-get-dist-update\n\n\n\n\n\n\n\nOutput\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo apt-get dist-upgrade\nReading package lists... Done\n...\nThe following packages were automatically installed and are no longer required:\n  gir1.2-goa-1.0 libxmlb1\nUse 'sudo apt autoremove' to remove them.                          ### this is the reason for the fourth command\n\nUbuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by\napplicable law.\n\nThe following NEW packages will be installed:\n  libxmlb2 linux-headers-5.4.0-169 linux-headers-5.4.0-169-generic linux-image-5.4.0-169-generic\n...\nThe following packages will be upgraded:\n  fwupd libfwupd2 libfwupdplugin5 linux-generic linux-headers-generic linux-headers-virtual linux-image-generic\n  linux-image-virtual linux-virtual python3-software-properties software-properties-common software-properties-gtk\n  ubuntu-advantage-tools\n13 upgraded, 8 newly installed, 0 to remove and 0 not upgraded.\n6 standard security updates\nNeed to get 80.2 MB of archives.\nAfter this operation, 379 MB of additional disk space will be used.\nDo you want to continue? [Y/n]                                      ### type y and press Enter\nGet:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu focal-updates/main amd64 ubuntu-advantage-tools amd64 30~20.04 [203 kB]\n...\nFound memtest86+ image: /boot/memtest86+.elf\nFound memtest86+ image: /boot/memtest86+.bin\ndone\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$\n\n\n\n\nThe fourth command, sudo apt autoremove, removes packages no longer used.\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~ \n$ sudo apt autoremove\n\n\n\n\n\n\n\nOutput - sudo aptautoremove\n\n\n\n\n\n\n\nOutput\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo apt autoremove\nReading package lists... Done\n..\nThe following packages will be REMOVED:\n  gir1.2-goa-1.0 libxmlb1 linux-headers-5.4.0-104 linux-headers-5.4.0-104-generic linux-image-5.4.0-104-generic\n  linux-modules-5.4.0-104-generic linux-modules-extra-5.4.0-104-generic\n0 upgraded, 0 newly installed, 7 to remove and 0 not upgraded.\nAfter this operation, 380 MB disk space will be freed.\nDo you want to continue? [Y/n]                                            ### type y and press Enter\n(Reading database ... 267814 files and directories currently installed.)\nRemoving gir1.2-goa-1.0:amd64 (3.36.1-0ubuntu1) ...\nRemoving libxmlb1:amd64 (0.1.15-2ubuntu1~20.04.1) ...\n...\nProgress: [ 67%] [###############################################################................................]\n...\ndone\nRemoving linux-modules-5.4.0-104-generic (5.4.0-104.118) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\nubuntu@instanceToBecomeAMI-Jorge.cloud-span.aws.york.ac.uk:~\n$\n\n\n\n\nThe fifth command, sudo do-release-upgrade, carries out the actual update to the next LTS release (version). But before entering the command, you need to reboot the system as otherwise you will receive the message: “You have not rebooted after updating a package which requires a reboot. Please reboot before upgrading.”\nTo reboot the system, enter the command sudo shutdown --reboot now, see the bar below. After 2 minutes login again with lginstance.sh ... ubuntu (press the UP arrow key to recall the command from the terminal history).\n\n\n\n\n\n\nReboot the system and ignore the “ERROR: cloud not login …”\n\n\n\n\n\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo shutdown --reboot now\n\nOnce you have entered the shutdown command you are going to see output below. Ignore the ERROR message. It pops up when the ssh connection is aborted out of shooting down the system as opposed to ending the connection normally — lginstance.sh checks that a connection ends normally and if it doesn’t, displays the error below and its usage message.\n\n\nOutput\n\n$ Connection to instancetobecomeami02-jorge.cloud-span.aws.york.ac.uk closed by remote host.\nConnection to instancetobecomeami02-jorge.cloud-span.aws.york.ac.uk closed.\n\nERROR: could not login, check the username ubuntu is correct - try with  \"ubuntu\" (with no quotes).\n----------------------------------------------\nlginstance.sh logs you in to an (AWS) instance using ssh.\n\nusage:\n\n    lginstance.sh  login-key-instanceName.pem  csuser/ubuntu/yourusername\n\n- login-key-instanceName.pem is the name (path) of the file containing the RSA login key\n  to access the instance.\n- the name of the instance to log you in is extracted from the name of the .pem file provided.\n- the domain name is extracted from the inputs/resourcesIDs.txt file.\n- Examples:\n  lginstance.sh courses/genomics01/outputs/login-keys/login-key-instance017.pem  csuser\n  lginstance.sh courses/genomics01/outputs/login-keys/login-key-instance017.pem  ubuntu\n\ncsuser@cloud-span-admin-instance:~\n$\n\n\n\n\nThe command sudo do-release-upgrade will take about 1 hour to upgrade the system, and throughout you will see a few questions for which you need to type y and press Enter or just press Enter for the upgrade to continue, see our comments (### …) inside the bar “Output — sudo do-release-upgrade” below. The last question is for the system to be restarted (rebooted), see our last comments inside the bar. Please enter the command:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~ \n$ sudo do-release-upgrade\n\n\n\n\n\n\n\nOutput - sudo do-release-upgrade\n\n\n\n\n\n\n\nOutput\n\nChecking for a new Ubuntu release\n...                                                 ### the screen will be cleared and started new \nReading cache\n\nChecking package manager\n\nContinue running under SSH?\n\nThis session appears to be running under ssh. It is not recommended\nto perform a upgrade over ssh currently because in case of failure it\nis harder to recover.\n\nIf you continue, an additional ssh daemon will be started at port\n'1022'.\nDo you want to continue?\n\nContinue [yN]y                                      ### type y and press Enter\n/etc/ssh/sshd_config line 16: Deprecated option UsePrivilegeSeparation\n...\nStarting additional sshd\n\nTo make recovery in case of failure easier, an additional sshd will\nbe started on port '1022'. If anything goes wrong with the running\nssh you can still connect to the additional one.\n\nTo continue please press [ENTER]                    ### press Enter\nReading package lists... Done\n...\nDo you want to start the upgrade?\n\n18 installed packages are no longer supported by Canonical. You can\nstill get support from the community.\n\n26 packages are going to be removed. 307 new packages are going to be\ninstalled. 1987 packages are going to be upgraded.\n\nYou have to download a total of 1,951 M. This download will take\nabout 4 minutes with your connection.\n\nInstalling the upgrade can take several hours. Once the download has\nfinished, the process cannot be canceled.\n\n Continue [yN]  Details [d]                         ### type y and press Enter\n...                                                 ### loads of text output will follow\n                ### and then 3 or 4 screenshots like the one below will be displayed\n                ### just press Enter to agree with the option shown - do not change anything\n                ### once you press Enter to each screenshot, a lot of tex output will follow\n\n\n\n\n.\n\n\n\n\nOutput\n\n...\nRemove obsolete packages?\n180 packages are going to be removed.\nRemoving the packages can take several hours.\n  Continue [yN]  Details [d]                        ### type y and press Enter\n..\nSystem upgrade is complete.\nRestart required\nTo finish the upgrade, a restart is required.\nIf you select 'y' the system will be restarted.\n  Continue [yN]                                     ### type y and press Enter - you will be logged out \n                                                    ### as when you rebooted the system\n                                                    ### wait 2 minutes and login again with \"lginstance.sh ... ubuntu\"\n\n\n\n\nOnce the system is restarted (1-2 minutes), login again with the command lginstance.sh .. ubuntu. When the Cloud-SPAN message appears, scroll up the screen with your mouse to see the new LTS version installed Ubuntu 22.04.3 LTS, see the output below. If the screen does not scroll up (it happens sometimes after rebooting the system), logout, open a new terminal, and login again.\nThe output below also shows two messages about updates: - “0 updates can be applied immediately” - “14 additional security updates can be applied with ESM Apps.”\nThe number of “additional security updates” you see may be different, as it depends on when you update the system. Cloud-SPAN is not interested in the “additional security updates ..” as it seems these updates need to be paid for. Follow the link below the second message if you are interested.\n\n\nOutput\n\nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 5.15.0-91-generic x86_64)           ### new version\n...\nExpanded Security Maintenance for Applications is not enabled.\n0 updates can be applied immediately.                                        ### no updates\n\n14 additional security updates can be applied with ESM Apps.                 ### other updates?\nLearn more about enabling ESM Apps service at https://ubuntu.com/esm\n...\n    W E L C O M E    T O    T H E\n     ____ _                 _         ______ _____   _    __   _\n    / ___| | ___  _   _  __| |       / ____ |  _  \\ / \\  |  \\ | |\n   | |   | |/ _ \\| | | |/ _` |  ___  \\___  \\| |_) '/ _ \\ | \\ \\| |\n   | |___| | (_) | |_| | (_| | |___| ____)  |  __ / ___ \\| |\\ | |\n    \\____|_|\\___/ \\___/ \\__,_|       \\_____/|_|  /_/   \\_|_| \\__|\n\n\n\nUpdating system software\nUpdating system software is carried out by running the script softwareInstall_genomics_ubuntusr.sh, which also installs the system libraries required by the Genomics end-user software applications installed in the ‘instance-to-become-AMI’.\nYou are logged in as the ubuntu user on your ‘instance-to-become-AMI’. Run softwareInstall_genomics_ubuntusr.sh as shown below:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ softwareInstall_genomics_ubuntusr.sh\n\n\n\nOutput\n\nsoftwareInstall_genomics_ubuntusr.sh upgrades and configures the Ubuntu system.\nThis script must be run before running the script that installs the genomics software analysis\ntools (softwareInstall_genomics_csuser.sh) in the csuser account.\nDo you want to continue (y/n)?:\n\nThe message in the output above will be explained shortly.\nYou only need to type y for the script to start running. See the output of the script in the bar below where our comments (###) highlight the main commands issued by the script.\n\n\n\n\n\n\nOutput — softwareInstall_genomics_ubuntusr.sh\n\n\n\n\n\n\n\nOutput\n\nDo you want to continue (y/n)?: y\nCreating directory logs\n\n(y): Configuring and upgrading system. Please wait:\nSaving installation logs to file:\nlogs/genomics_sftwre_install_ubuntuuser.sh20240119.154518.txt          ### logs file, see with less -R filename\n\nHit:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu jammy InRelease\nGet:2 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n...\nGet:8 https://esm.ubuntu.com/infra/ubuntu jammy-infra-updates InRelease [7,449 B]\nFetched 2,558 kB in 1s (2,470 kB/s)\nReading package lists...\nsudo apt-get upgrade                                                   ### install library\nReading package lists...\n...\nCalculating upgrade...\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\nsudo apt-get install libssl-dev                                        ### install library\nReading package lists...\n...\nSuggested packages:\n  libssl-doc\nThe following NEW packages will be installed:\n  libssl-dev\n0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 2,373 kB of archives.\nAfter this operation, 12.4 MB of additional disk space will be used.\nGet:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu jammy-updates/main amd64 libssl-dev amd64 3.0.2-0ubuntu1.12 [2,373 kB]\nFetched 2,373 kB in 0s (34.4 MB/s)\n...\nsudo apt-get install libncurses5-dev                                   ### install library\nReading package lists...\nThe following additional packages will be installed:\n...\nsudo apt-get install -y autoconf automake make gcc perl zlib1g-dev libbz2-dev liblzma-dev libcurl4-gnutls-dev libssl-dev libperl-dev libgsl0-dev                                                    ### install library\nReading package lists...\n...\nUse 'sudo apt autoremove' to remove it.                                ### sudo apt autoremove\nThe following additional packages will be installed:\n  autotools-dev libgsl27 libgslcblas0 m4\nSuggested packages:\n...\nsudo apt-get install python3-pip                                       ### install library\nReading package lists...\nThe following package was automatically installed and is no longer required:\n  libcurl3-nss\nUse 'sudo apt autoremove' to remove it.                                ### sudo apt autoremove\nThe following additional packages will be installed:\n...\nsudo apt-get install docker.io                                         ### install library\n...\nUse 'sudo apt autoremove' to remove it.                                ### sudo apt autoremove \nThe following additional packages will be installed:\n...\nsudo groupadd docker                                                   ### install library\ngroupadd: group 'docker' already exists\nsudo usermod -aG docker csuser                                         ### install library\nsudo apt-get update                                                    ### \n...\nsudo apt-get upgrade                                                   ###\n...\nThe following package was automatically installed and is no longer required:\n  libcurl3-nss\nUse 'sudo apt autoremove' to remove it.                                ### sudo apt autoremove  is needed\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n---------------------\nDONE system-wide setting and upgrade for csuser to install genomics software.\nCHECK the log file logs/genomics_sftwre_install_ubuntuuser.sh20240119.154518.txt.\n\nYou need to reboot the system (sudo shutdown --reboot now), login again, and\ncheck the Ubuntu system message above the Cloud-SPAN message. If the system message says that\nsome \"updates can be applied immediately\", run this command:\n\nsudo apt-get --with-new-pkgs upgrade --yes                             ### may also be needed\n\nYou may need to reboot, login again  and run the above command a few times until the system\nmessage reads \"0 updates can be applied immediately\" - you may want to make a not the command\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$\n\n\n\n\nAt the end, the output of the script suggests that we run: - sudo apt autoremove and - sudo apt-get --with-new-pkgs upgrade --yes if, after rebooting the system, you find that the system welcome message says that some (1 or more) “updates can be applied immediately”, and that we reboot the system and run that command again until that message reads “0 updates can be applied immediately”.\nLet’s run sudo apt autoremove first (before rebooting the system):\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~ \n$ sudo apt autoremove\n\n\n\nOutput\n\nDo you want to continue? [Y/n] y\n(Reading database ... 223713 files and directories currently installed.)\nRemoving libcurl3-nss:amd64 (7.81.0-1ubuntu1.15) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.5) ...\n\nLet’s now reboot the system (and ignore the message “ERROR: could not ..” as before):\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~ \n$ sudo shutdown --reboot now\n\n\n\nOutput\n\n$ Connection to instancetobecomeami02-jorge.cloud-span.aws.york.ac.uk closed by remote host.\nConnection to instancetobecomeami02-jorge.cloud-span.aws.york.ac.uk closed.\n\nERROR: could not login, check the username ubuntu is correct - try with  \"ubuntu\" (with no quotes).\n...\n\nLogin again with lginstance.sh ... ubuntu after 2 minutes or so, scroll up the screen with the mouse right button and check whether the system welcome message says that some (1 or more) “updates can be applied immediately”. If that is the case, (1) run the command sudo apt-get --with-new-pkgs upgrade --yes, (2) reboot the system, (3) login again, and (4) check that message again. Repeat those four steps until that message reads “0 updates can be applied immediately”.\n\n\nOutput\n\nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 5.15.0-91-generic x86_64)\n...\nExpanded Security Maintenance for Applications is not enabled.\n0 updates can be applied immediately.      ### should be zero otherwise run: sudo apt-get --with-new-pkgs upgrade --yes\n17 additional security updates can be applied with ESM Apps.\n    W E L C O M E    T O    T H E\n     ____ _                 _         ______ _____   _    __   _\n    / ___| | ___  _   _  __| |       / ____ |  _  \\ / \\  |  \\ | |\n   | |   | |/ _ \\| | | |/ _` |  ___  \\___  \\| |_) '/ _ \\ | \\ \\| |\n   | |___| | (_) | |_| | (_| | |___| ____)  |  __ / ___ \\| |\\ | |\n    \\____|_|\\___/ \\___/ \\__,_|       \\_____/|_|  /_/   \\_|_| \\__|\n\n\n\nInstalling other applications and removing applications — first part\nRecall that the script softwareInstall_genomics_ubuntusr.sh (run in the previous section) carries out both updating system software and installing the system libraries required by the Genomics software applications already installed in your ‘instance-to-become-AMI’.\nAs such, if you are to install other (not yet installed Genomics or other kind of) applications that require installing system libraries under our approach, you will need to modify that script, adding to it the corresponding sudo commands that install the required system libraries. Doing so as in the example below corresponds to the first part of installing other applications (alluded in the heading above). The second part corresponds to modifying the script softwareInstall_genomics_csuser.sh, adding to it the commands that install the “other applications” in the csuser account as described in step 6.3. Updating end-user software applications.\n\nModifying softwareInstall_genomics_ubuntusr.sh to install other system libraries\nThe script softwareInstall_genomics_ubuntusr.sh has these three main sections: - at the top, the “about” message and the option to cancel or let the script run the update - in the middle, the sudo commands that install the required system libraries - at the end, the message on “what to do next”: rebooting the system, etc.\nYou will add in the middle section the sudo commands to install the system libraries required by the “other applications” you want to install.\nFor example, let’s suppose that the Genomics application bcftools is not yet installed in the ‘instance-to-become-AMI’ that you are configuring and that you need to install it as described in the bcftools install page. This page (visited on 22 Jan 2024) has two sections: “For the impatient” and “Detailed instructions”.\n\n\n\n\n\n\nbcftools — “For the impatient” install instructions\n\n\n\n\n\n\n\nCode\n\ngit clone --recurse-submodules https://github.com/samtools/htslib.git\ngit clone https://github.com/samtools/bcftools.git\ncd bcftools\n # The following is optional:\n #   autoheader && autoconf && ./configure --enable-libgsl --enable-perl-filters\nmake\n\n\n\n\nWe obviously tried first the instructions for the impatient but as these failed, we proceeded to follow the detailed instructions for Debian/Ubuntu (there are detailed instructions for other versions of Linux, for MacOs and for Windows). The detailed instructions for Debian/Ubuntu are these:\n\n\nCode\n\n sudo apt-get update        # Ensure the package list is up to date\n sudo apt-get install autoconf automake make gcc perl zlib1g-dev libbz2-dev liblzma-dev libcurl4-gnutls-dev libssl-dev libperl-dev libgsl0-dev\n\nEventually, the instructions for the impatient were placed in the script softwareInstall_genomics_csuser.sh (see step 6.3. Updating end-user software applications.), and the detailed instructions (the two sudo apt-get .. commands above) in the script softwareInstall_genomics_ubuntusr.sh, as shown in the bar below (comments in CAPITALS are not part of the script, please read them):\n\n\n\n\n\n\nsoftwareInstall_genomics_ubuntusr.sh — bcftools system libraries install\n\n\n\n\n\n#!/usr/bin/env bash\n# system-wide configuration and upgrade needed for csuser to install genomics software.\nsource colour_utils_functions.sh     # to add colour to some messages and more   ### FUNCTION message IS IN THIS FILE \n...\nmessage \"\\n$(colour lb $(basename $0)) upgrades and configures the Ubuntu system. \nThis script must be run before running the script that installs the $(colour lb genomics) software analysis\ntools (softwareInstall_genomics_csuser.sh) in the csuser account.\" \nread -n 1 -p \"Do you want to continue (y/n)?: \" option                           ### CONTINUE OPTION\n...                                                         \nlogfile=logs/genomics_sftwre_install_ubuntuuser.sh`date '+%Y%m%d.%H%M%S'`.txt    ### LOG FILE NAME\nmessage \"\\n($option): Configuring and upgrading system. Please wait:\" $logfile\n...\nsudo apt-get update -y | tee -a $logfile                                         ### FIRST SYSTEM update AND upgrade   \nmessage \"$(colour lg \"sudo apt-get upgrade\")\" $logfile                           ### AND AGAIN AT THE END. SO YOUR SUDO\nsudo apt-get upgrade -y | tee -a $logfile                                        ### COMMANDS MUST BE IN-BETWEEN THESE\n...                                                                              ### UPDATES AND UPGRADES\nmessage \"$(colour lg \"sudo apt-get install libncurses5-dev\")\" $logfile           ### INSTALLING OTHER SYSTEM LIBRARIES\nsudo apt-get install -y libncurses5-dev | tee -a $logfile                        \n               ########### BCFTOOLS SUDO COMMANS TO INSTALL REQUIRED SYSTEM LIBRARIES\nmessage \"$(colour lg \"sudo apt-get install -y autoconf automake make gcc perl zlib1g-dev libbz2-dev liblzma-dev libcurl4-gnutls-dev libssl-dev libperl-dev libgsl0-dev\")\" $logfile\nsudo apt-get install -y autoconf automake make gcc perl zlib1g-dev libbz2-dev liblzma-dev libcurl4-gnutls-dev libssl-dev libperl-dev libgsl0-dev | tee -a $logfile\n               ########### END OF BCFTOOLS SUDO COMMANS TO INSTALL REQUIRED SYSTEM LIBRARIES\nmessage \"$(colour lg \"sudo apt-get install python3-pip\")\" $logfile               ### INSTALLING OTHER SYSTEM LIBRARIES\nsudo apt install -y python3-pip | tee -a $logfile\n... \nmessage \"$(colour lg \"sudo apt-get update\")\" $logfile                             ### FINAL SYSTEM update AND upgrade \nsudo apt-get update -y  | tee -a $logfile                                         ### \nmessage \"$(colour lg \"sudo apt-get upgrade\")\" $logfile                            ###\nsudo apt-get upgrade -y | tee -a $logfile       \n#------------------------ DONE\nmessage \"$(colour lg \"---------------------\")\n$(colour lg \"DONE system-wide setting and upgrade\") for csuser to install genomics software.\nCHECK the log file $(colour lb \"$logfile\").\n..\nYou may need to reboot, login again  and run the above command a few times until the system\nmessage reads \\\"0 updates can be applied immediately\\\" - you may want to make a not the command\\n\"  $logfile\n\n\n\nYou will notice that, in adding the sudo commands that install the required system libraries by bcftools (or by any other application for that matter), we also added the following code: - message \"$(colour lg \"sudo apt-get -y install LIBRARY-NAMES\")\" $logfile so that the command is written to the log file. - the -y option between sudo apt-get intall and the name of the libraries to install, so that the script will run without stopping to ask anything. - the code | tee -a $logfile at the end (of the library names) so that the output of the sudo command is printed to the screen but also appended to the log file by the tee program.\nYou will also notice that the first sudo command required by bcftools, namely, sudo apt-get update, is run twice, at the beginning and at the end of the script for all the system libraries installed.\n\n\nModifying softwareInstall_genomics_ubuntusr.sh to remove system libraries\nWe have not removed any system library explicitly but have stopped installing some libraries by commenting the commands that install them.\nIf you would like to remove some system libraries, place the relevant commands in between the two system update-upgrades (at the beginning and at the end) of the script.\n\n\nShould you modify softwareInstall_genomics_ubuntusr.sh before running it?\nYes, you should add as many of the commands that install the libraries required by the applications you want installed in your ‘instance-to-become-AMI’.\nHowever, don’t expect that a single run of the script will suffice. Once you modify and run the script, you will then have to modify and run the script that installs the applications in the csuser account and then check that the applications run. They may or may not run, as they may depend on other applications being present. For instance, bcftools and samtools both require that you also install htslib — but we realised this after installing bcftools.\nThus, more likely you will be iterating modifying and running softwareInstall_genomics_ubuntusr.sh and softwareInstall_genomics_csuser.sh, and testing that all applications run. These scripts just help this iterating being more efficient and documented — add plenty of comments.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#changing-the-end-user-username",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#changing-the-end-user-username",
    "title": "AMIs Management",
    "section": "6.2 Changing the end-user username",
    "text": "6.2 Changing the end-user username\nIf you are to change the Cloud-SPAN csuser to a username of your liking, you first need to perform updating system software — updating to the next LTS is not necessary but would be convenient.\nIf you plan to install other applications not yet installed in the Genomics AMI, or to remove some or all of the applications in the Genomics AMI, or both, first change the end-user username (after updating system software) and then update the Genomics applications as described in step 6.3 Updating end-user software applications. This will give you and stable instance with your new username. Then install and/or remove applications through updating system software and updating end-user software applications, that is, through modifying and running the scripts softwareInstall_genomics_ubuntusr.sh and softwareInstall_genomics_csuser.sh. In so doing, you may need to increase the storage as described in step 6.4 Increasing storage size, but it is straightforward.\n\nCreate your new end-user username\nLogin as the ubuntu user to your ‘instance-to-become-AMI’ (use lginstance .. ubuntu) and enter the command below (we are using nwuser as our new username — choose yours). The option --disabled-password means that the new username will not be required a password but a login key to login to an instance created from the AMI you are configuring.\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo adduser --disabled-password nwuser\n\nYou will be asked to enter a Full Name, Room Number, etc. Type what you like and press Enter until the prompt appears again:\n\n\nOutput\n\nAdding user `nwuser' ...\nAdding new group `nwuser' (1004) ...\nAdding new user `nwuser' (1002) with group `nwuser' ...\nCreating home directory `/home/nwuser' ...\nCopying files from `/etc/skel' ...\nChanging the user information for nwuser\nEnter the new value, or press ENTER for the default\n        Full Name []: New User\n        Room Number []:\n        Work Phone []:\n        Home Phone []:\n        Other []:\nIs the information correct? [Y/n] Y\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n\nMove all the files in the Cloud-SPAN csuser home directory to the home directory of your new username with the sudo mv .. command below:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo mv -f /home/csuser/{.,}* /home/nwuser\n\nYou will see the output below. Ignore it, the files have been moved. The purpose of moving the files is to have your new user configured as the csuser is, which includes its login key so that the new user can login, but there are other configurations files that we don’t want to setup from scratch. Also, it is not convenient to copy the files with cp as it will take much longer and we are going to delete the csuser anyway.\n\n\nOutput\n\nmv: cannot move '/home/csuser/.' to '/home/nwuser/.': Device or resource busy\nmv: '/home/csuser/..' and '/home/nwuser/..' are the same file\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n\nChange the ownership of all the files in the new user home directory and list the files with ls -al to check the new user is the owner:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ sudo chown -R nwuser:nwuser /home/nwuser\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ ls -al ../nwuser/\n\nThe output should look like this one:\n\n\nOutput\n\ntotal 164\ndrwxr-xr-x 23 nwuser nwuser 4096 Jan 23 15:35 .\ndrwxr-xr-x  6 root   root   4096 Jan 23 15:21 ..\ndrwxrwxr-x  5 nwuser nwuser 4096 Mar 18  2022 .backup\n-rw-------  1 nwuser nwuser 6910 Jan 20 16:46 .bash_history\n-rw-r--r--  1 nwuser nwuser  220 Jul 29  2015 .bash_logout\n-rw-r--r--  1 nwuser nwuser 4074 Jan  9 12:09 .bashrc\ndrwxrwxr-x  2 nwuser nwuser 4096 Mar  1  2022 bin\ndrwxrwxr-x  2 nwuser nwuser 4096 Oct 26  2021 .conda\n...\n\nDelete the csuser:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:/home\n$ sudo deluser --remove-home csuser\n\n\n\nOutput\n\nLooking for files to backup/remove ...\nRemoving files ...\nRemoving user `csuser' ...\nWarning: group `csuser' has no more members.\nDone.\n\n\n\nChange csuser for your new username everywhere in the script ~/bin/usersAuthorizedKeys-activate.sh\nYou are logged in as the ubuntu user and that script is in your home (~) bin directory. You have the nano and emacs text editors to do that change. These are the lines in that file where you need to change csuser for your new username:\n\n\nOutput\n\n...\necho Copying .ssh/authorized_keys to user csuser\nsudo cp ~/.ssh/authorized_keys ~/../csuser/.ssh\nsudo chown -R csuser:csuser ~/../csuser/.ssh/authorized_keys\n\nOnce your ‘instance-to-become-AMI’ does become an AMI, and instances are created from it, the Script aws_instances_configure.sh will configure access to each instance by remotely invoking in each instance the script /home/ubuntu/bin/usersAccessKeys-setup-MAIN.sh. This script in turn invokes the script that you have just modified which, as you can see by the modified code lines, will then copy the instance authorised keys to your new username so that it can be logged in with the same key used with the ubuntu user.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#edit-or-delete-the-message-of-the-day-file",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#edit-or-delete-the-message-of-the-day-file",
    "title": "AMIs Management",
    "section": "Edit or delete the “message of the day” file",
    "text": "Edit or delete the “message of the day” file\nIf you want to edit or delete the Cloud-SPAN welcome message shown below, you need to edit or delete the file /etc/motd. It is write protected so you need to run nano or emacs as sudo: sudo emacs /etc/motd.\n\n\n\n\n\n\nThe Cloud-SPAN welcome message:\n\n\n\n\n\n    _____________________________\n\n   W E L C O M E    T O    T H E\n\n\n    ____ _                 _         ______ _____   _    __   _\n   / ___| | ___  _   _  __| |       / ____ |  _  \\ / \\  |  \\ | |\n  | |   | |/ _ \\| | | |/ _` |  ___  \\___  \\| |_) '/ _ \\ | \\ \\| |\n  | |___| | (_) | |_| | (_| | |___| ____)  |  __ / ___ \\| |\\ | |\n   \\____|_|\\___/ \\___/ \\__,_|       \\_____/|_|  /_/   \\_|_| \\__|\n\n\n\n   G E N O M I C S     C O U R S E     E N V I R O N M E N T\n   _____________________________________________________________\n\n   Scroll up with the mouse for information before this welcome\n\n   Type \"csguide\" (and the Enter (↵) key) for some guidance\n   _____________________________________________________________\n\n\n\n\nLogin to your new username\nYou can now logout (from the ubuntu user) and login to your new username thus:\n\n\nCode\n\ncsuser@cloud-span-admin-instance:~\n$ lginstance.sh amis/ami02-myFirstAMIConfig/outputs/login-keys/login-key-instanceToBecomeAMI02-Jorge.pem nwuser",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#updating-end-user-software-applications",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#updating-end-user-software-applications",
    "title": "AMIs Management",
    "section": "6.3 Updating end-user software applications",
    "text": "6.3 Updating end-user software applications\nUpdating end-user software applications is carried out by running the script softwareInstall_genomics_csuser.sh as the csuser (or as the new user you may have created). The script should be run only after updating system software by running the script softwareInstall_genomics_ubuntusr.sh as the ubuntu user.\nWe have changed csuser to nwuser, logged in thus lginstance.sh .. nwuser, and are about to update end-user software applications.\nWe will first delete the file and directory shown below as they are of no use and were created out of changing the username (the file examples.destop) and updating to the next LTS (the directory snap).\n\n\nOutput\n\nnwuser@instanceToBecomeAMI02-Jorge:~\n$ ls \nbin  examples.desktop  shell_data  snap  software\n$ rm -r examples.desktop snap/\n$ ls\nbin  shell_data  software\n\n\nInstall Genomics applications or print versions installed\nThe script softwareInstall_genomics_csuser.sh can be run with one of two options that are displayed when the script is run on its own (with no parameters):\n\n\nCode\n\nnwuser@instanceToBecomeAMI02-Jorge:~\n$ softwareInstall_genomics_csuser.sh\n\n\n\nOutput\n\nsoftwareInstall_genomics_csuser.sh installs all genomics software analysis tools.\n\nThis script should be run before creating a genomics AMI, and after running the script that\nupdates the Ubuntu system, softwrInstall_genomics_ubuntusr.sh, in the ubuntu account.\n    usage:\n             softwareInstall_genomics_csuser.sh [go][versions]\n             - use option go to install all applications - you will have the option to cancel.\n             - use option versions to see the versions installed.\n\nThe option go installs the applications while the option versions runs all the applications installed to print their versions. The option versions will only work if you have logged in as csuser — it will not work if you have logged in with your new user name. This is because installing the applications configures some files, to locate the applications, using the username running the installing. Hence, as the applications in your ‘instance-to-become-AMI’ were installed using the csuser, they will not be found if run with another username. See the output of the script run with the versions option on the instance we have changed the username (nwuser) and on an instance where csuser has not been changed.\n\n\nCode\n\nnwuser@instanceToBecomeAMI02-Jorge:~\n$ softwareInstall_genomics_csuser.sh versions\n\n\n\n\n\n\n\nOutput (nwuser) — softwareInstall_genomics_csuser.sh versions\n\n\n\n\n\nVersions of genomics software tools installed:\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: line 233: conda: command not found\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: line 234: python: command not found\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: line 235: fastqc: command not found\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: /home/nwuser/.local/bin/cutadapt: /home/csuser/.miniconda3/bin/python3: bad interpreter: No such file or directory\ncutadapt\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: line 237: bwa: command not found\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: line 239: samtools: command not found\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: line 241: bcftools: command not found\nvcfutils.pl   (prints no version - is installed by bcftools)\n/home/nwuser/.local/bincsaws/softwareInstall_genomics_csuser.sh: line 244: trimmomatic: command not found\ntrimmomatic\nnwuser@instanceToBecomeAMI02-Jorge:~\n\n\n\n\n\n\n\n\n\nOutput (csuser) — softwareInstall_genomics_csuser.sh versions\n\n\n\n\n\nVersions of genomics software tools installed:\nconda 4.10.3\nPython 3.9.5\nFastQC v0.11.9\ncutadapt 3.5\n\nProgram: bwa (alignment via Burrows-Wheeler transformation)\nVersion: 0.7.17-r1188\n\nsamtools 1.13\nUsing htslib 1.13\n\nbcftools 1.14-3-g756e636\nUsing htslib 1.14-1-g7060387\n\nvcfutils.pl   (prints no version - is installed by bcftools)\ntrimmomatic 0.39\n\n\n\n\n\nInstalling the Genomics applications\nThe script softwareInstall_genomics_csuser.sh installs the latest applications from scratch for any user: csuser or your new username — it does not try to only update the applications for csuser. The applications are installed in the directories ~/software and ~/.miniconda3, and before the installation begins, all files in those directories are deleted.\nThe script runs in two steps. Step 1 configures the software package manager conda and installs a few applications that do not require conda to be installed.\nStep 2 installs the applications that require conda but, before running step 2, you must logout and login again for the conda configuration made in step 1 to take place. If after step 2 some applications cannot be found, you mostly likely forgot to logout and login in before — happened to us.\nYou run both steps in exactly the same way:\n\n\nCode\n\nnwuser@instanceToBecomeAMI02-Jorge:~\n$ softwareInstall_genomics_csuser.sh go\n\n\n\n\n\n\n\nOutput (nwuser) — softwareInstall_genomics_csuser.sh go ### step 1\n\n\n\n\n\nsoftwareInstall_genomics_csuser.sh is about to INSTALL genomics software, step 1 (of 2)\n\nDo you want to continue (y/n)?: y                            ### press y\nCreating directory .genomics_sftw_logs\n\nRunning step 1 (of 2) of genomics software installation\n\nCleaning directory ~/software (rm -fr ~/software/*)\nremoving (current) conda\ncd\nrm -rf ~/.miniconda3\nrm -rf ~/.conda ~/.continuum\ninstalling conda\n...                                                           ### LOADS OF OUTPUT\nCompleted step 1 (of 2) of genomics software install.\n\nPlease logout and login again, and then run this script again (as below) to complete step 2:\n\n     softwareInstall_genomics_csuser.sh go\n\n\n\nLogout and login, and then run the script again the same way: softwareInstall_genomics_csuser.sh go and check the output at the end.\n\n\n\n\n\n\nOutput (nwuser) — softwareInstall_genomics_csuser.sh go ### step 2\n\n\n\n\n\nsoftwareInstall_genomics_csuser.sh is about to INSTALL genomics software, step 2 (of 2)\n\nDo you want to continue (y/n)?:                                 ### press y \n...                                                             ### some output\nCompleted step 2 (of 2) of genomics software install.\n\nPlease logout and login again for environment changes to take effect.\n\nThe installation logs of steps 1 and 2 are in this file:\n/home/nwuser/.genomics_sftw_logs/genomics_sftwre_install.sh20240108.160203.txt\n\n\n\nLogout and login (!), and now run the script with the versions option to check the versions installed: softwareInstall_genomics_csuser.sh  versions:\n\n\n\n\n\n\nOutput (nwuser) — softwareInstall_genomics_csuser.sh  versions ### vers installed\n\n\n\n\n\n$ softwareInstall_genomics_csuser.sh versions\nVersions of genomics software tools installed:\nconda 23.11.0\nPython 3.11.7\nFastQC v0.12.1\ncutadapt 4.6\n\nProgram: bwa (alignment via Burrows-Wheeler transformation)\nVersion: 0.7.17-r1188\n\nsamtools 1.19-3-g62195d3\nUsing htslib 1.19-3-g67f3ab0f\n\nbcftools 1.19-16-g25dc6e2a\nUsing htslib 1.19-3-g67f3ab0f\n\nvcfutils.pl   (prints no version - is installed by bcftools)\ntrimmomatic 0.39\n\n\n\n\n\nInstalling other applications and removing applications — second part\nRecall that if you are to install other (not yet installed) applications that require installing system libraries you need to: - add the sudo commands that install the system libraries to the script softwareInstall_genomics_ubuntusr.sh (first part) and also - add the commands that install the applications to the script softwareInstall_genomics_csuser.sh (second part)\nClearly, if the other applications you are to install do not require system libraries, then you don’t need to go through the first part, but you still need to go through the second part, as described below.\n\nModifying softwareInstall_genomics_csuser.sh to install other applications\nThe script softwareInstall_genomics_csuser.sh has two main sections:\n\nat the beginning, a number of functions that each installs an application and possibly other related application/s, and the function print_all_versions() that runs all the installed applications to print their version.\nat the end, a kind of main function that:\n\ndisplays the usage message\nprocesses the entered option: go or versions\nruns the versions option, invoking print_all_versions()\nruns the go option, Step 1 or 2, calling the relevant functions that install the application in each step.\n\n\nThe organisation into functions facilitates trying out different options in installing applications, as you only need to comment or uncomment a function invocation in the main function to deactivate or activate installing an application. The script softwareInstall_genomics_csuser.sh is relatively small, as it only installs 9 applications, of which only 3 are somewhat complex to install. But the organisation into functions was first designed to configure the Cloud-SPAN Metagenomics AMI, which required installing over 25 applications.\nTo modify the script in order to install other applications, for each application you need to:\n\ndesign and add the function that installs the application (go option)\nadd the invocation of the function in the main function in Step 1 or Step 2 (go option)\nadd to print_all_versions() the invocation of the application to print its version (versions option)\n\nFor example, let’s suppose again that the Genomics application bcftools is not yet installed in the ‘instance-to-become-AMI’ that you are configuring and that you need to install it as described in the bcftools install page which, you will recall has two sections:\n\n“For the impatient” and\n“Detailed instructions”\n\nYou may also recall that we mentioned that “Eventually, the instructions for the impatient were placed in the script softwareInstall_genomics_csuser.sh (see step 6.3. …)”, etc. So the following describes somewhat what we did and why to modify the script to install bcftools.\nThe code in the three bars below show (1) the commands “For the impatient” to install bcftools (shown before but repeated here for convenience), (2) our function install_bcftools() containing those commands and a few more that install bcftools locally and write the commands used and their outputs to a log file (using the message function), and (3) the invocation of install_bcftools() by the main function; check our comments in CAPITALS.\n\n\n\n\n\n\nbcftools — “For the impatient” (FTI) install instructions\n\n\n\n\n\n\n\nCode\n\ngit clone --recurse-submodules https://github.com/samtools/htslib.git\ngit clone https://github.com/samtools/bcftools.git\ncd bcftools\n # The following is optional:\n #   autoheader && autoconf && ./configure --enable-libgsl --enable-perl-filters\nmake\n\n\n\n\nNote the following differences between the instructions “For the impatient” (FTI) and their coding in our function install_bcftools(). The first FTI command, git clone --recurse-submodules https://github.com/samtools/htslib.git, is not used by our function install_bcftools(). This is because htslib is installed before bcftools and thus is already available when bcftools is being installed. We installed htslib separately because it is also needed by samtools and we seem to remember that htslib could not be found if it was installed inside bcftools through that first command.\nThe optional, fourth FTI command, authoheader && autoconf && ./configure .., is three commands in one and is run by install_bcftools(), but we had to put the three commands in between parentheses () for the output of the three commands to be properly printed to the screen and written to the log file.\nThe third of those three commands, ./configure, is missing the second option --enable-perl-filters in install_bcftools(). We eliminated it because the installation failed every time we used it, and the three commands were optional anyway.\nThe point is: installing other applications will sometimes go nicely smoothly, but sometimes you will have to improvise. The scripts only help in trying different things more efficiently. There are plenty of comments in the scripts including the links to the instructions to install each application.\n\n\n\n\n\n\ninstall_bcftools() function in softwareInstall_genomics_csuser.sh\n\n\n\n\n\n\n\nCode\n\nfunction install_bcftools() {\n    message \"installing `colour lb bcftools`\" $1\n    message \"cd ~/software\" $1\n    cd ~/software                                                    ### INSTALL IN ~/software\n    message \"git clone https://github.com/samtools/bcftools.git\" $1\n    git clone https://github.com/samtools/bcftools.git               ### SECOND FTI COMMAND\n    message \"cd bcftools/\" $1\n    cd bcftools/                                                     ### THIRD FTI COMMAND\n    message \"( autoheader && autoconf && ./configure --enable-libgsl ) # no --enable-perl-filters, let Annabel and Sarah F. know\" $1\n                                                                      ### OPTIONAL FOURTH FTI COMMAND\n    ( autoheader && autoconf && ./configure --enable-libgsl ) 2&1 | tee -a $1 \n    message \"make\" $1\n    make  2&1 | tee -a $1                                           ### FIFTH FTI COMMAND\n\n    # make local install\n    message \"cd ~/bin\" $1\n    cd ~/bin\n\n    message \"ln -sf ~/software/bcftools/bcftools        # local install ONLY\" $1\n    ln -sf ~/software/bcftools/bcftools             # local install ONLY\n    message \"ln -sf ~/software/bcftools/misc/vcfutils.pl # local install ONLY\" $1\n    ln -sf ~/software/bcftools/misc/vcfutils.pl         # local install ONLY\n    \n    message \"cd\" $1\n    cd\n    message \"vcfutils.pl    (likely not to print a version)\" $1\n    vcfutils.pl 2&1 | tee -a $1\n}\n\n\n\n\nIn the bar below, the invocation of install_bcftools() by the main function was placed in Step 1 (of 2) because bcftools is installed through its own installation script which is run with the make program. The other applications installed in Step 1, conda, htslib, and samtools, are installed likewise with their own installation scripts.\nThe applications installed in Step 2 need conda or pip to be installed. conda and pip are software package managers. conda is installed locally in the end-user directory ~/.miniconda3 and it also installs pip, but we also installed first some libraries at system level with the command sudo apt-get install python3-pip in the script softwareInstall_genomics_ubuntusr.sh.\n\n\n\n\n\n\ninvocation of install_bcftools() by the main function in softw..csuser.sh\n\n\n\n\n\n\n\nCode\n\n...\n### carry out step 1 or 2 of genomics software install\nif [ ! -f ~/.genomics_sftw_logs/continue_install ]; then           ### STEP 1\n    # Step 1 as the file ../continue_install (which signals step 2) does not exist\n    logfile=~/.genomics_sftw_logs/genomics_sftwre_install.sh`date '+%Y%m%d.%H%M%S'`.txt \n    message \"\\nRunning step 1 (of 2) of genomics software installation\" $logfile\n    message \"\\nCleaning directory ~/software (rm -fr ~/software/*)\" $logfile\n    rm -fr ~/software/*\n    install_conda $logfile\n    install_htslib $logfile         ### kind of library needed by samtools and other programs\n    install_samtools $logfile       \n    install_bcftools $logfile                                      ### INVOCATION OF BCFTOOLS\n    # vcfutils.pl is installed by bcftools\n    echo $logfile .genomics_sftw_logs/continue_install\n    message \"\\n$(colour lb \"Completed step 1\") (of 2) of genomics software install.\\n\nPlease logout and login again, and then run this script again (as below) to complete step 2:\\n\n     $(colour lb $(basename $0)) go\\n\" $logfile\n    exit 0\n    \nelse                                                               ### STEP 1\n    # Step 2 as the file ../continue_install (which signals step 2) exists\n    logfile=`cat ~/.genomics_sftw_logs/continue_install`  ### continue using previous logfile\n    message \"\\nRunning step 2 (of 2) of genomics software install\" $logfile\n    install_python $logfile      ### the miniconda version is usually more recent than the ubuntu system one\n    install_fastqc $logfile      \n    install_cutadapt $logfile       \n    install_bwa $logfile             \n    install_trimmomatic $logfile            \n    message \"\\n$(colour lb \"Completed step 2\") (of 2) of genomics software install.\\n\nPlease logout and login again for environment changes to take effect.\\n\nThe installation logs of steps 1 and 2 are in this file:\n$logfile\\n\" $logfile\n    rm .genomics_sftw_logs/continue_install\n    ### $(basename $0) versions         ### logout and login again is needed otherwise it may print errors.\n    exit 0\n\n\n\n\nThus, if the other applications you are to install do not require a package manager to install them, you invoke the functions that install each application in Step 1.\nIf the other applications you are to install do require a package manager to install them, you invoke the functions that install the package managers in Step 1 (if they are other than conda and pip), and the functions that install each application in Step 2.\nTo remove applications, you only need to comment the invocation of the functions that install the applications you want removed.\nFinally, check also the following scripts, which have plenty of examples as to how to install some applications and the system libraries they require: - softwareInstall_metagen_ubuntu1v.sh - softwareInstall_metagen_csuser1v.sh - softwareInstall_metagen_ubuntu2v.sh - softwareInstall_metagen_csuser2v.sh\nThese scripts were used to create the first Metagenomics AMI configuring (starting with) an ‘instance-to-become-AMI’ created from the 30GB Genomics AMI. However, remember that running these scripts will not give you a properly configured Metagenomics AMI because, as mentioned in the Background to our approach to configuring instances-to-become-AMIs, some Metagenomics experts configured some databases and applications both in between and after running the two versions of the scripts.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#increasing-storage-size-1",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#increasing-storage-size-1",
    "title": "AMIs Management",
    "section": "6.4 Increasing storage size",
    "text": "6.4 Increasing storage size\nIncreasing storage size is carried out by running the script aws_storageEBS_increase.sh as the ubuntu user in the instance whose storage you want to increase — yes, while the instance is running. Before running the script, you need both to install and to configure the aws CLI in the instance with programmatic access credentials, that is: (1) an access key ID and (2) a secret access key — which you will remember are generated with your AWS IAM user account in the AWS Console.\nYou don’t need to create new credentials to increase the storage of your ‘instance-to-become-AMI’ (though you can if you want to). We are going to use the same credentials we have been using to create instances in this and the last episode. We are going to copy such credentials to our ‘instance-to-become-AMI’, increase the storage, and then delete the credentials. We want to delete the credentials because we don’t want them to be in each instance created from the AMI that your ‘instance-to-become-AMI’ will be. You could invalidate the credentials in the AWS Console instead, or both. It’s up to you. We are going to delete them as mentioned.\nWe are going to perform the following: - delete current aws CLI — an old version installed at system level - install latest aws CLI — locally in the ubuntu user - configure aws CLI — copying the credentials you have been using - increase storage — running aws_storageEBS_increase.sh\n\nDelete the current aws CLI installed at system level\nLogin to your ‘instance-to-become-AMI’ as the ubuntu user (lginstance.sh .. ubuntu) and enter the commands below to delete the old version of the aws CLI.\nFor clarity and convenience we will be showing the prompt only before the first command and below each command its output:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ which aws\n/usr/local/bin/aws\n\n$ ls -l /usr/local/bin/aws*\nlrwxrwxrwx 1 root root 37 May  8  2022 /usr/local/bin/aws -/usr/local/aws-cli/v2/current/bin/aws\nlrwxrwxrwx 1 root root 47 May  8  2022 /usr/local/bin/aws_completer -/usr/local/aws-cli/v2/current/bin/aws_completer\n\n$ ls -a /usr/local/aws-cli\n.  ..  v2 \n\n$ sudo rm -rf /usr/local/bin/aws /usr/local/bin/aws_completer /usr/local/aws-cli      ### no output: deleted\n$ which aws\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~                        ### no path: aws no longer found\n\nFirst, the which command gives us the path of the aws CLI. With that path, ls -l ../aws* tells whether aws is a link and whether there are other AWS programs installed. There are two AWS programs installed which are both links: aws and aws_completer. Both links point to the actual programs which are stored in the directory: /usr/local/aws-cli\nWith ls -a /usr/local/aws-cli we check whether there is anything else stored in that directory: only version v2 is therein. With sudo rm .. we then delete the directory and the links to the programs we found earlier. To prevent mistakes, we copy-pasted the paths of the directory and the links to the sudo rm .. command.\n\n\nInstall the latest aws CLI locally in the ubuntu account\nEnter the following command to install the latest version of the aws CLI and press y to continue:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ aws_cli_install_update_linux.sh\n\naws_cli_install_update_linux.sh  installs or updates the AWS CLI and the AWS completer locally.\n\nDo you want to continue (y/n)?:                             ### press y to continue\n...                                                         ### quite some output\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~    ### install finished\n$ which aws                                                 ### where was installed\n/home/ubuntu/.local/bincsaws/aws\n\n$ ls -l .local/bincsaws/                                    ###\ntotal 256\nlrwxrwxrwx 1 ubuntu ubuntu    56 Jan 26 11:23 aws -/home/ubuntu/.local/bincsaws/aws-cli2/v2/current/bin/aws\ndrwxrwxr-x 3 ubuntu ubuntu  4096 Jan 26 11:23 aws-cli2\n-rwxrwxr-x 1 ubuntu ubuntu  1536 Jan  9 16:23 aws_cli_install_update_linux.sh\nlrwxrwxrwx 1 ubuntu ubuntu    66 Jan 26 11:23 aws_completer -/home/ubuntu/.local/bincsaws/aws-cli2/v2/current/bin/aws_completer\n... \n\n$ ls .aws\nls: cannot access '.aws': No such file or directory\n\nThe aws CLI is installed along with the Scripts, in the directory ~/.local/bincsaws/.\nThe last command ls .aws is to show that the directory ~/.aws does not exist and thus the aws CLI is not configured. It can run but any commands issued to access AWS resources will fail.\nWe need to logout and login again for the installation configuration to take place (see the last line of the file ~/.bashrc which was added to activate the aws_completer).\nWe also need to logout to copy the credentials which are in the ~/.aws directory in the machine where we created the ‘instance-to-become-AMI’.\n\n\nConfigure the aws CLI: copy the AWS credentials you have been using to your ‘instance-to-become-AMI’\nYou have logged out of your ‘instance-to-become-AMI’; you are now in the machine where you created that instance — our prompt has changed to csuser@cloud-span-admin-instance:~ in the code below.\nThe command ls -a .aws (while in our home directory) shows that the directory ~/.aws exists and has two files: config and credentials.\n\n\nCode\n\ncsuser@cloud-span-admin-instance:~\n$ ls -a .aws\nconfig  credentials\n\n\nCopy the .aws directory to your ‘instance-to-become-AMI’\nEnter the command cptoInstance.sh as shown below to copy the .aws directory to your ‘instance-to-become-AMI’, passing as parameters (1) the -u option, (2) the path of the login key file of your ‘instance-to-become-AMI’ and (3) the name of the directory to copy, .ami.\n\n\nCode\n\ncsuser@cloud-span-admin-instance:~\n$ cptoInstance.sh -u amis/ami02-myFirstAMIConfig/outputs/login-keys/login-key-instanceToBecomeAMI02-Jorge.pem .aws\ncredentials                                                           100%  116   231.4KB/s   00:00\nconfig                                                                100%   43    92.6KB/s   00:00\n\ncptoinstance.sh works similarly to lginstance.sh in that you need to specify the login key of the instance to which you want to copy a file or directory. The -u option means to copy to the ubuntu account as opposed to the csuser account which is the default.\nYou also have available the script cpfromInstance.sh which works similarly but copying from an instance to the machine where you issue the command.\nFor this course, we only modified lginstance.sh to work with any username — it used to work only for the usernames ubuntu and csuser. That is, if you changed the end-user username, you need to modify cptoInstance.sh and cpfromInstance.sh to work with your new username.\n\n\n\n\n\n\nHow cptoInstance.sh works:\n\n\n\n\n\ncptoInstance.sh was installed along with the Scripts on your computer — it is already installed on your AWS instance if you are attending a workshop using a Cloud-SPAN AWS account. Run cptoInstance.sh with no parameters to see its usage message.\n\n\nCode\n\n$ cptoInstance.sh\n\n\n\nOutput\n\ncptoInstance.sh copies a local file/directory to the csuser account of an AWS instance.\n\nusage:\n\n  cptoInstance.sh [-l][-u][-v] login-key-instanceName.pem  localFile/DirName  [remoteFile/DirName]\n\n- NB: copying an individual file or link overwrites remote ones if they exist; remote directories are\n  not overwritten if they exist but the copy is suffixed thus: remoteDirName-CopyYYYYMMDD.HHMMSS.\n- use -l to copy links within directories as links (otherwise files pointed to by links are copied).\n- use -u to copy to the 'ubuntu' account instead (of the 'csuser' account).\n- use -v (verbose) to see what's going on and the copy command used.\n- login-key-instanceName.pem is the name (path) of the file containing the RSA login key to access\n  the instance. The name of the instance to copy to is extracted from this name.\n- if remoteFile/DirName is not specified, the copy will be named as the localFile/DirName and copied\n  at the home directory in the instance.\n- Examples:\n  cptoInstance.sh gc_data/outputs/login-keys/login-key-instance017.pem  data/shell_data\n  - copies (file/dir) data/shell_data to instance017.cloud-span.aws.york.ac.uk:/home/csuser/shell_data\n\n  cptoInstance.sh -u gc_data/outputs/login-keys/login-key-instance017.pem  shell_data  shell_data2\n  - copies  data/shell_data to instance017.cloud-span.aws.york.ac.uk:/home/ubuntu/shell_data2\n\nDon’t forget to use the Tab key to complete cptoInstance.sh and the file paths of the login key and the file/dir to copy.\n\n\n\n\n\n\nIncrease the storage of your ‘instance-to-become-AMI’\nLogin to your ‘instance-to-become-AMI’ as the ubuntu user (lginstance.sh .. ubuntu).\nEnter the following commands to check:\n\nthe credentials have been copied\nhow to run the script aws_storageEBS_increase.sh and\nthe current size of the instance storage\n\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ ls .aws                                        ### we have the credentials\nconfig  credentials\n\n$ aws_storageEBS_increase.sh                     ### with no parameters the usage message is printed\naws_storageEBS_increase.sh increases the size of the instance disk (EBS storage) and the file system\nup to the given number of GigaBytes (GB) if such number is larger than the current size of the disk.\n\nusage:     aws_storageEBS_increase.sh  newSizeOfDiskInGBs\n\n  Example:       aws_storageEBS_increase.sh 120\n - increases the size of the disk and file system to be of 120 GB.\n - the current disk size must be smaller than 120 GB.\n - note that the file system size may be shown as slightly smaller than disk space:\n   try command: \"df -h .\"\n\n$ df -h .                                        ### print file system disk space usage in GB\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/nvme0n1p1   30G   21G  7.5G  74% /\n\nWe need to run aws_storageEBS_increase.sh specifying the size in GBs that we want the storage and file system to be. The last command df -h . prints the current size of the storage which is 30 GBs.\nWe are going to increase the storage by 5 GB only. So we need to run the script specifying 35 GB:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ aws_storageEBS_increase.sh 35\nDisk current size is 30 and is going to be increased to 35.\nDo you want to continue (y/n)?: y                                   ### press y to continue\nIncreasing disk size from 30 to 35 GBs. Please wait:\naws ec2 modify-volume --size 35 --volume-id vol-0481c9665b82e23ad logs/aws_storage_increase.sh20240126.160253.txt 2&1\nSuccess extending disk size but must wait for optimisation phase:\nnot yet, status: modifying\nStatus: optimizing is enough, proceeding ..\nChecking new size with command \"/dev/nvme0n1\":\nnewDiskSize 35\nIncreasing partition and file system:\nCHANGED: partition=1 start=2048 old: size=62912479 end=62914527 new: size=73398239 end=73400287\nresize2fs 1.46.5 (30-Dec-2021)\nFilesystem at /dev/nvme0n1p1 is mounted on /; on-line resizing required\nold_desc_blocks = 2, new_desc_blocks = 3\nThe filesystem on /dev/nvme0n1p1 is now 9174779 (4k) blocks long.\n\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/nvme0n1p1   35G   21G   13G  63% /\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n\nThe script aws_storageEBS_increase.sh runs the command df -h . at the end to show the new size of the storage and file system.\n\nTry to increase the storage again\nIf you try to increase the storage again shortly after you have increased it, the script will fail as in the example below where we tried to increase the storage to be 40 GB:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ aws_storageEBS_increase.sh 40\n\nDisk current size is 35 and is going to be increased to 40.\nDo you want to continue (y/n)?: y\nIncreasing disk size from 35 to 40 GBs. Please wait:\naws ec2 modify-volume --size 40 --volume-id vol-0481c9665b82e23ad logs/aws_storage_increase.sh20240126.164447.txt 2&1\nError extending disk size, please check the log file logs/aws_storage_increase.sh20240126.164447.txt for details.\n\nCheck the log file specified in the last line of your output. You will find a message like the following (among other information), stating that you need to wait some time to increase the storage again:\n\n\nOutput\n\n...\nAn error occurred (VolumeModificationRateExceeded) when calling the ModifyVolume operation: You've reached the maximum modification rate per volume limit. Wait at least 6 hours between modifications per EBS volume.\n...\n\n\n\nTry to run the script after deleting the AWS credentials\nIf you try to increase the storage after deleting the AWS credentials, the script will fail thus:\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ rm -fr .aws                                ### delete the credentials\n$ aws_storageEBS_increase.sh 40              ### try to increase storage\n\nUnable to locate credentials. You can configure credentials by running \"aws configure\".\n/home/ubuntu/.local/bincsaws/aws_storageEBS_increase.sh: line 88: [: -ge: unary operator expected\nDisk current size is  and is going to be increased to 40.\nDo you want to continue (y/n)?: y\nIncreasing disk size from  to 40 GBs. Please wait:\naws ec2 modify-volume --size 40 --volume-id  logs/aws_storage_increase.sh20240126.180719.txt 2&1\nError extending disk size, please check the log file logs/aws_storage_increase.sh20240126.180719.txt for details.\n\nThe first line of the output above, “Unable to locate credentials. You can configure credentials .. [etc.]”, corresponds to the first aws (CLI) command in the script which is in charge of recovering the volume-id of the storage so that the second aws command in the script, aws ec2 modify-volume --size 40 --volume-id (shown in the output above), can request the storage increase. As shown by the output, the first aws command failed for lack of credentials, but the script continued and eventually failed in the second aws command for a syntax error. Check your log file, and the script aws_storageEBS_increase.sh in your text editor, particularly the first and second invocations to aws. The script is “working”, but should have aborted execution when the first aws command failed.\nCan you fix the script before creating your AMI?",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  },
  {
    "objectID": "docs/lesson02-managing-aws-instances/03-ami-management.html#before-creating-your-ami-last-trimmings-and-deleting-all-login-keys",
    "href": "docs/lesson02-managing-aws-instances/03-ami-management.html#before-creating-your-ami-last-trimmings-and-deleting-all-login-keys",
    "title": "AMIs Management",
    "section": "6.5 Before creating your AMI: last trimmings and deleting all login keys",
    "text": "6.5 Before creating your AMI: last trimmings and deleting all login keys\nYou have configured your ‘instance-to-become-AMI’ with regard to: - system software (patches, libraries and possibly a new LTS version of Ubuntu Linux) - possibly changed the end-user username - end-user software, possibly adding other applications and deleting others - increased storage size\nYou may have had to iterate through those steps a few times to get to the configuration you needed for your AMI. For instance, given that reducing storage size is difficult, you may have had to increase storage gradually, creating intermediate AMIs to roll back, if needed.\nThe last tasks to carry out are these:\n\nperforming minor trimmings you want in each instance created from your AMI\nrebooting your instance to become AMI and login again as the ubuntu user — this is to ensure all changes take effect\ndeleting the login keys you have been using to login to your ‘instance-to-become-AMI’ so that they are not present in each instance created from your AMI. It is a recommended best practice to delete all previously used keys just before creating an AMI for improving security and reducing the likelihood of “man-in-the-middle” attacks.\nstopping your ‘instance-to-become-AMI’ with sudo shootdown now — you will not be able to login again to your ‘instance-to-become-AMI’, as you will have deleted all login keys.\ncreating your AMI in the AWS Console as you did in Section 2 (Create an AMI and make it Public in the AWS Console).\ntesting your AMI — creating an instance from your new AMI and login to the instance as you did in the previous episode Instances Management Tasks Using the Scripts. Recall that we manage the instances we create in three directories: amis, courses, tests. So you may want to use the tests directory to create the instance from your new AMI, for example: tests/t001-test-instance-ami02/inputs. The point of such a name is to “link” the elements involved: it is a test instance (not a course nor an AMI instance), created from the second AMI you created (in this course).\n\n\nMinor trimmings you may want in each instance created from your AMI\nYou may want some data or a few admin scripts installed in each instance created from your AMI, just as we installed all the Scripts in the Genomics AMI in the directory ~/.local/bincsaws, of both the ubuntu user and the csuser.\nYou can use the scripts cptoInstance.sh and cpfromInstance.sh to copy files between your admin computer and your ‘instance-to-become-AMI’ you are configuring. Alternatively, you can use GitHub to place whatever you want in your ‘instance-to-become-AMI’, and then git-clone it into your instance, see the section Configure Your Terminal Environment, which shows how we installed the Scripts in the instance that became the Genomics AMI.\nYou may also want to trim the prompt, the colours of the prompt, or the colours used to display directory names, link files, etc. The configuration files you need to trim are ~/.bashrc and ~/.dircolors.\nThese are the lines in ~/.bashrc of the csuser and ubuntu user you need to modify to trim the prompt and its colours:\n\n\nCode\n\n### csuser (nwuser)\n    PS1='${debian_chroot:+($debian_chroot)}\\[\\033[00;37m\\]\\u\\[\\033[00;33m\\]@\\[\\033[00;32m\\]\\h\\[\\033[00m\\]:\\[\\033[00;36m\\]\\w\\[\\033[00m\\] \\n\\$ '\n\n### ubuntu user\n    PS1='${debian_chroot:+($debian_chroot)}\\[\\033[00;37m\\]\\u\\[\\033[00;33m\\]@\\[\\033[00;32m\\]\\H\\[\\033[00m\\]:\\[\\033[00;36m\\]\\w\\[\\033[00m\\] \\n\\$ '\n\nThe strange strings are colour codes (you need to google to change them). The prompt elements are (1) the username \\u\\, (2) the at @ symbol, (3) the host name \\h\\ in csuser and full host name \\H\\ in the ubuntu user, (4) a semi-colon :, (5) the working directory \\w\\, and (6) the dollar sign \\$ at the end.\nThe newline \\n character just before the dollar sign, \\n\\$, is what makes the dollar sign appear on its own in a new line. If you delete the newline, then you will have a single line prompt and will enter commands in the same line.\nIf you move the newline after the dollar sign like so \\$\\n, you will have a two line prompt: the first line ending with the dollar sign, and the second line clean waiting for you to type your command — this simplifies copy-pasting commands as you don’t have to get rid of the dollar sign.\nTo change the colours used in displaying file and directory names, open the file ~/.dircolors and search for the string DIR, then play with different colour combinations for different types of files.\nIf you change ~/.bashrc or ~/.dircolors, you need to logout and login again for the changes to take effect. Changes will only apply to the username you logged in to make the changes.\n\n\nRebooting your instance for any changes to take effect\nYou are now done with changes. Please reboot the system as shown below and login again in 2-3 minutes as the ubuntu user (lginstance.sh .. ubuntu), as you need sudo privileges for the next task: deleting all login keys.\n\n\nCode\n\n$ sudo shutdown --reboot now\n\nYou may have already seen a message like the one below after updating the operating system in your personal computer: “Your computer needs to restart for changes to take effect.”\n\n\nDeleting all login keys\nYou are logged in as the ubuntu user. Please enter the commands below to delete all the loging keys (details in remove-ssh-host-key-pairs):\n\n\nCode\n\nubuntu@instanceToBecomeAMI02-Jorge.cloud-span.aws.york.ac.uk:~\n$ ls /etc/ssh/*_key /etc/ssh/*_key.pub                                 ### what are we deleting?\n/etc/ssh/ssh_host_dsa_key      /etc/ssh/ssh_host_ecdsa_key.pub    /etc/ssh/ssh_host_rsa_key\n/etc/ssh/ssh_host_dsa_key.pub  /etc/ssh/ssh_host_ed25519_key      /etc/ssh/ssh_host_rsa_key.pub\n/etc/ssh/ssh_host_ecdsa_key    /etc/ssh/ssh_host_ed25519_key.pub\n\n$ sudo shred -u /etc/ssh/*_key /etc/ssh/*_key.pub                      ### silent, no output\n\n\n$ ls /etc/ssh/*_key /etc/ssh/*_key.pub                                 ### check no more keys\nls: cannot access '/etc/ssh/*_key': No such file or directory\nls: cannot access '/etc/ssh/*_key.pub': No such file or directory\n\n$ cat .ssh/authorized_keys                                           ### delete key we've been using\nCtrl-d\n\nEntering the last command, cat .ssh/authorized_keys, and then typing the keys Ctrl and d simultaneously to exit the cat command, has the effect of emptying out the file .ssh/authorized_keys, thus deleting the login key we have been using to login to our ‘instance-to-become-AMI’.\nOnce an instance is launched from your new AMI, the AWS will append to that file the login key created for the instance, and then, the script aws_instances_configure.sh will invoke the script /home/ubunutu/usersAccessKeys-setup-MAIN.sh in the instance to copy that file into the equivalent one in the csuser (or your new user account) to enable it to login.\nYou now need to:\n\nshootdown your instance, entering this command: sudo shootdown now — you will be logged and won’t be able to login again.\ngo to the AWS Console and create an AMI out of your instance as suggested above within the tests directory, etc.\ncreate an instance with your new AMI and login to your instance and check the configuration you did: username, storage size, prompt, scripts, etc. You have created instances before, so do similarly, and remember to change the ami-id in the file resourcesIDs.txt with the ami-id of your instance.\n\nThat’s all from us regarding AMIs management. Get in touch if you need to.",
    "crumbs": [
      "Home",
      "Managing AWS Instances",
      "AMIs Management"
    ]
  }
]